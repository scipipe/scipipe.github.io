{
    "docs": [
        {
            "location": "/",
            "text": "SciPipe\n\n\n\n\nSciPipe is a library\nfor writing \nscientific Workflows\n,\nin the \nGo programming language\n.\n\n\nSo, when you have multiple commandline applications that need to be run after\neach other in a chain, where one program depends on the output of the other,\nyou can define these dependencies in SciPipe. SciPipe will then take care of\nrunning the programs in the right order, at the right time, and produce audit\nreports about exactly what was run.\n\n\nSciPipe is especially well suited for complex dependency networks, where you\nalso don't always know how many outputs are produced by a particular program.\nSciPipe also gives you a lot of flexibility in how your files are named.\nSciPipe has many more benefits, which are listed under the \nBenefits\nsection\n below.\n\n\nProject links\n\n\n\n\nFor source code, see the \ngithub repository\n\n\nFor reporting issues, please use the \nissue tracker\n\n\nFor general questions, see the \nmailing list\n\n\n\n\nAn example workflow\n\n\nLet's look at a simple toy example of a workflow, to get a feel for what\nwriting workflows with SciPipe looks like:\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nsp\n \n\"github.com/scipipe/scipipe\"\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \n// Initialize processes\n\n    \nfooWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foowriter\"\n,\n \n\"echo 'foo' > {o:foo}\"\n)\n\n    \nfooToBar\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foo2bar\"\n,\n \n\"sed 's/foo/bar/g' {i:foo} > {o:bar}\"\n)\n\n    \nsink\n \n:=\n \nsp\n.\nNewSink\n()\n \n// Will just receive file targets, doing nothing\n\n\n    \n// Add output file path formatters for the components created above\n\n    \nfooWriter\n.\nSetPathStatic\n(\n\"foo\"\n,\n \n\"foo.txt\"\n)\n\n    \nfooToBar\n.\nSetPathExtend\n(\n\"foo\"\n,\n \n\"bar\"\n,\n \n\".bar\"\n)\n\n\n    \n// Connect network\n\n    \nfooToBar\n.\nIn\n[\n\"foo\"\n].\nConnect\n(\nfooWriter\n.\nOut\n[\n\"foo\"\n])\n\n    \nsink\n.\nConnect\n(\nfooToBar\n.\nOut\n[\n\"bar\"\n])\n\n\n    \n// Add to a pipeline runner and run\n\n    \npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n    \npipeline\n.\nAddProcesses\n(\nfoowriter\n,\n \nfooToBar\n,\n \nsink\n)\n\n    \npipeline\n.\nRun\n()\n\n\n}\n\n\n\n\n\n\nRunning the example workflow\n\n\nLet's assume we put the code in a file named \nmyfirstworkflow.go\n and run it.\nThen it can look like this:\n\n\n[\nsamuel test\n]\n$ go run myfirstworkflow.go\nAUDIT   \n2016\n/06/09 \n17\n:17:41 Task:foowriter    Executing command: \necho\n \n'foo'\n > foo.txt.tmp\nAUDIT   \n2016\n/06/09 \n17\n:17:41 Task:foo2bar      Executing command: sed \n's/foo/bar/g'\n foo.txt > foo.txt.bar.tmp\n\n\n\n\n\nAs you see, scipipe displays all the shell commands it has executed based on the defined workflow.\n\n\nBenefits\n\n\nSome benefits of SciPipe that are not always available in other scientific workflow systems:\n\n\n\n\nEasy-to-grasp behaviour:\n Data flowing through a network.\n\n\nFlexible:\n Processes that wrap command-line programs and scripts can be combined with\n  processes coded directly in Golang.\n\n\nEfficient:\n Workflows are compiled into static compiled code, that runs fast.\n\n\nPortable:\n Workflows can be distributed as go code to be run with the \ngo run\n command\n  or compiled into stand-alone binaries for basically any unix-like operating system.\n\n\nCustom file naming:\n SciPipe gives you full control over how file names are produced,\n  making it easy to understand and find your way among the output files of your computations.\n\n\nInherently simple:\n SciPipe uses the in-built concurrency primitives in\n  the Go programming language (go-routines and channels) to create an\n  \"implicit\" scheduler, which means very little additional infrastructure code.\n  This means that the code is easy to modify and extend.\n\n\nSupports streaming:\n You can choose to stream selected outputs via Unix FIFO files, to avoid temporary storage.\n\n\nParallel:\n SciPipe leverages both pipeline parallelism between multiple\n  processes, and task parallelism when there is multiple inputs to a process,\n  to make your computations complete as fast as possible, utilizing all the CPU\n  cores available.\n\n\nNotebookeable:\n Works well in \nJupyter notebooks\n,\n  using the \ngophernotes kernel\n.\n\n\nConcurrent:\n Each process runs in an own light-weight thread, and is not blocked by\n  operations in other processes, except when waiting for inputs from upstream processes.\n\n\nEasy to debug:\n Since everything in SciPipe is just Go code, you can\n  easily use the \ngdb debugger\n (with the \ncgdb\n  interface\n for easier use) to\n  step through your program at any detail, as well as all the other excellent\n  debugging tooling for Go (See eg\n  \ndelve\n and\n  \ngodebug\n), or just use \nprintln()\n\n  statements at any place in your code. In addition, you can easily turn on\n  detailed debug output from SciPipe's execution itself, by just turning\n  on debug-level logging with \nscipipe.InitLogDebug()\n in your \nmain()\n method.\n\n\n\n\nKnown limitations\n\n\n\n\nThere are still a number of missing good-to-have features, for workflow design. See the \nissues\n tracker for details.\n\n\nThere is not yet support for the \nCommon Workflow Language\n, but that is also something that we plan to support in the future.\n\n\n\n\nConnection to flow-based programming\n\n\nFrom Flow-based programming, SciPipe uses the ideas of separate network (workflow dependency graph)\ndefinition, named in- and out-ports, sub-networks/sub-workflows and bounded buffers (already available\nin Go's channels) to make writing workflows as easy as possible.\n\n\nIn addition to that it adds convenience factory methods such as \nscipipe.NewFromShell()\n which creates ad hoc processes\non the fly based on a shell command pattern, where  inputs, outputs and parameters are defined in-line\nin the shell command with a syntax of \n{i:INPORT_NAME}\n for inports, and \n{o:OUTPORT_NAME}\n for outports\nand \n{p:PARAM_NAME}\n for parameters.\n\n\nPublications mentioning SciPipe\n\n\n\n\nSee \na poster on SciPipe\n, presented at the \ne-Science Academy in Lund, on Oct 12-13 2016\n.\n\n\nSee \nslides from a recent presentation of SciPipe for use in a Bioinformatics setting\n.\n\n\nThe architecture of SciPipe is based on an \nflow-based\n  programming\n like\n  pattern in pure Go presented in\n  \nthis\n and\n  \nthis\n\n  blog posts on Gopher Academy.\n\n\n\n\nRelated tools\n\n\nFind below a few tools that are more or less similar to SciPipe that are worth worth checking out before\ndeciding on what tool fits you best (in approximate order of similarity to SciPipe):\n\n\n\n\nNextFlow\n\n\nLuigi\n/\nSciLuigi\n\n\nBPipe\n\n\nSnakeMake\n\n\nCuneiform\n\n\n\n\nAcknowledgements\n\n\n\n\nThis library is heavily influenced/inspired by (and might make use of on in the future),\n  the \nGoFlow\n library by \nVladimir Sibirov\n.\n\n\nIt is also heavily influenced by the \nFlow-based programming\n by \nJohn Paul Morrison\n.\n\n\nThis work is financed by faculty grants and other financing for Jarl Wikberg's \nPharmaceutical Bioinformatics group\n of Dept. of\n  Pharmaceutical Biosciences at Uppsala University, and to a smaller part also by \nSwedish Research Council\n through the Swedish \nBioinformatics Infastructure for Life Sciences in Sweden\n.\n\n\nSupervisor for the project is \nOla Spjuth\n.\n\n\nBig thanks to \nEgon Elbre\n for very helpful input on the design of the internals of the pipeline, and processes, which simplified the implementation a lot.",
            "title": "SciPipe Overview"
        },
        {
            "location": "/#scipipe",
            "text": "SciPipe is a library\nfor writing  scientific Workflows ,\nin the  Go programming language .  So, when you have multiple commandline applications that need to be run after\neach other in a chain, where one program depends on the output of the other,\nyou can define these dependencies in SciPipe. SciPipe will then take care of\nrunning the programs in the right order, at the right time, and produce audit\nreports about exactly what was run.  SciPipe is especially well suited for complex dependency networks, where you\nalso don't always know how many outputs are produced by a particular program.\nSciPipe also gives you a lot of flexibility in how your files are named.\nSciPipe has many more benefits, which are listed under the  Benefits\nsection  below.",
            "title": "SciPipe"
        },
        {
            "location": "/#project-links",
            "text": "For source code, see the  github repository  For reporting issues, please use the  issue tracker  For general questions, see the  mailing list",
            "title": "Project links"
        },
        {
            "location": "/#an-example-workflow",
            "text": "Let's look at a simple toy example of a workflow, to get a feel for what\nwriting workflows with SciPipe looks like:  package   main  import   ( \n     sp   \"github.com/scipipe/scipipe\"  )  func   main ()   { \n     // Initialize processes \n     fooWriter   :=   sp . NewFromShell ( \"foowriter\" ,   \"echo 'foo' > {o:foo}\" ) \n     fooToBar   :=   sp . NewFromShell ( \"foo2bar\" ,   \"sed 's/foo/bar/g' {i:foo} > {o:bar}\" ) \n     sink   :=   sp . NewSink ()   // Will just receive file targets, doing nothing \n\n     // Add output file path formatters for the components created above \n     fooWriter . SetPathStatic ( \"foo\" ,   \"foo.txt\" ) \n     fooToBar . SetPathExtend ( \"foo\" ,   \"bar\" ,   \".bar\" ) \n\n     // Connect network \n     fooToBar . In [ \"foo\" ]. Connect ( fooWriter . Out [ \"foo\" ]) \n     sink . Connect ( fooToBar . Out [ \"bar\" ]) \n\n     // Add to a pipeline runner and run \n     pipeline   :=   sp . NewPipelineRunner () \n     pipeline . AddProcesses ( foowriter ,   fooToBar ,   sink ) \n     pipeline . Run ()  }",
            "title": "An example workflow"
        },
        {
            "location": "/#running-the-example-workflow",
            "text": "Let's assume we put the code in a file named  myfirstworkflow.go  and run it.\nThen it can look like this:  [ samuel test ] $ go run myfirstworkflow.go\nAUDIT    2016 /06/09  17 :17:41 Task:foowriter    Executing command:  echo   'foo'  > foo.txt.tmp\nAUDIT    2016 /06/09  17 :17:41 Task:foo2bar      Executing command: sed  's/foo/bar/g'  foo.txt > foo.txt.bar.tmp  As you see, scipipe displays all the shell commands it has executed based on the defined workflow.",
            "title": "Running the example workflow"
        },
        {
            "location": "/#benefits",
            "text": "Some benefits of SciPipe that are not always available in other scientific workflow systems:   Easy-to-grasp behaviour:  Data flowing through a network.  Flexible:  Processes that wrap command-line programs and scripts can be combined with\n  processes coded directly in Golang.  Efficient:  Workflows are compiled into static compiled code, that runs fast.  Portable:  Workflows can be distributed as go code to be run with the  go run  command\n  or compiled into stand-alone binaries for basically any unix-like operating system.  Custom file naming:  SciPipe gives you full control over how file names are produced,\n  making it easy to understand and find your way among the output files of your computations.  Inherently simple:  SciPipe uses the in-built concurrency primitives in\n  the Go programming language (go-routines and channels) to create an\n  \"implicit\" scheduler, which means very little additional infrastructure code.\n  This means that the code is easy to modify and extend.  Supports streaming:  You can choose to stream selected outputs via Unix FIFO files, to avoid temporary storage.  Parallel:  SciPipe leverages both pipeline parallelism between multiple\n  processes, and task parallelism when there is multiple inputs to a process,\n  to make your computations complete as fast as possible, utilizing all the CPU\n  cores available.  Notebookeable:  Works well in  Jupyter notebooks ,\n  using the  gophernotes kernel .  Concurrent:  Each process runs in an own light-weight thread, and is not blocked by\n  operations in other processes, except when waiting for inputs from upstream processes.  Easy to debug:  Since everything in SciPipe is just Go code, you can\n  easily use the  gdb debugger  (with the  cgdb\n  interface  for easier use) to\n  step through your program at any detail, as well as all the other excellent\n  debugging tooling for Go (See eg\n   delve  and\n   godebug ), or just use  println() \n  statements at any place in your code. In addition, you can easily turn on\n  detailed debug output from SciPipe's execution itself, by just turning\n  on debug-level logging with  scipipe.InitLogDebug()  in your  main()  method.",
            "title": "Benefits"
        },
        {
            "location": "/#known-limitations",
            "text": "There are still a number of missing good-to-have features, for workflow design. See the  issues  tracker for details.  There is not yet support for the  Common Workflow Language , but that is also something that we plan to support in the future.",
            "title": "Known limitations"
        },
        {
            "location": "/#connection-to-flow-based-programming",
            "text": "From Flow-based programming, SciPipe uses the ideas of separate network (workflow dependency graph)\ndefinition, named in- and out-ports, sub-networks/sub-workflows and bounded buffers (already available\nin Go's channels) to make writing workflows as easy as possible.  In addition to that it adds convenience factory methods such as  scipipe.NewFromShell()  which creates ad hoc processes\non the fly based on a shell command pattern, where  inputs, outputs and parameters are defined in-line\nin the shell command with a syntax of  {i:INPORT_NAME}  for inports, and  {o:OUTPORT_NAME}  for outports\nand  {p:PARAM_NAME}  for parameters.",
            "title": "Connection to flow-based programming"
        },
        {
            "location": "/#publications-mentioning-scipipe",
            "text": "See  a poster on SciPipe , presented at the  e-Science Academy in Lund, on Oct 12-13 2016 .  See  slides from a recent presentation of SciPipe for use in a Bioinformatics setting .  The architecture of SciPipe is based on an  flow-based\n  programming  like\n  pattern in pure Go presented in\n   this  and\n   this \n  blog posts on Gopher Academy.",
            "title": "Publications mentioning SciPipe"
        },
        {
            "location": "/#related-tools",
            "text": "Find below a few tools that are more or less similar to SciPipe that are worth worth checking out before\ndeciding on what tool fits you best (in approximate order of similarity to SciPipe):   NextFlow  Luigi / SciLuigi  BPipe  SnakeMake  Cuneiform",
            "title": "Related tools"
        },
        {
            "location": "/#acknowledgements",
            "text": "This library is heavily influenced/inspired by (and might make use of on in the future),\n  the  GoFlow  library by  Vladimir Sibirov .  It is also heavily influenced by the  Flow-based programming  by  John Paul Morrison .  This work is financed by faculty grants and other financing for Jarl Wikberg's  Pharmaceutical Bioinformatics group  of Dept. of\n  Pharmaceutical Biosciences at Uppsala University, and to a smaller part also by  Swedish Research Council  through the Swedish  Bioinformatics Infastructure for Life Sciences in Sweden .  Supervisor for the project is  Ola Spjuth .  Big thanks to  Egon Elbre  for very helpful input on the design of the internals of the pipeline, and processes, which simplified the implementation a lot.",
            "title": "Acknowledgements"
        },
        {
            "location": "/install/",
            "text": "Install\n\n\nInstall Go\n\n\nFirst install Go by following instructions on \nthis page\n.\n  - I typically install to a custom location (\n~/go\n for the go tools, and \n~/code/go\n for my own go-projects).\n  - If you want to install (which means, untar the go tarball) to \n~/go\n just like me, you should put the following in your \n~/.bashrc\n file:\n\n\n# Go stuff\n\n\nexport\n \nGOROOT\n=\n~/go\n\nexport\n \nGOPATH\n=\n~/code/go\n\nexport\n \nPATH\n=\n$GOROOT\n/bin:\n$PATH\n\n\nexport\n \nPATH\n=\n$GOPATH\n/bin:\n$PATH\n\n\n\n\n\n\nInstall SciPipe\n\n\nInstall SciPipe by running the following shell command:\n\n\ngo get github.com/scipipe/scipipe/...\n\n\n\n\n\nN.B:\n Don't miss the \n...\n, or you won't get the \nscipipe\n helper tool.\n\n\nInitialize a new workflow file\n\n\nNow, you should be able to write code like in the example below, in files ending with \n.go\n.\n\n\nThe easiest way to get started is to let the scipipe tool generate a starting point for you:\n\n\nscipipe new myfirstworkflow.go\n\n\n\n\n\n... which you can then edit to your liking.\n\n\nRun your workflow\n\n\nTo run a \n.go\n file, use \ngo run\n:\n\n\ngo run myfirstworkflow.go",
            "title": "Installing SciPipe"
        },
        {
            "location": "/install/#install",
            "text": "",
            "title": "Install"
        },
        {
            "location": "/install/#install-go",
            "text": "First install Go by following instructions on  this page .\n  - I typically install to a custom location ( ~/go  for the go tools, and  ~/code/go  for my own go-projects).\n  - If you want to install (which means, untar the go tarball) to  ~/go  just like me, you should put the following in your  ~/.bashrc  file:  # Go stuff  export   GOROOT = ~/go export   GOPATH = ~/code/go export   PATH = $GOROOT /bin: $PATH  export   PATH = $GOPATH /bin: $PATH",
            "title": "Install Go"
        },
        {
            "location": "/install/#install-scipipe",
            "text": "Install SciPipe by running the following shell command:  go get github.com/scipipe/scipipe/...  N.B:  Don't miss the  ... , or you won't get the  scipipe  helper tool.",
            "title": "Install SciPipe"
        },
        {
            "location": "/install/#initialize-a-new-workflow-file",
            "text": "Now, you should be able to write code like in the example below, in files ending with  .go .  The easiest way to get started is to let the scipipe tool generate a starting point for you:  scipipe new myfirstworkflow.go  ... which you can then edit to your liking.",
            "title": "Initialize a new workflow file"
        },
        {
            "location": "/install/#run-your-workflow",
            "text": "To run a  .go  file, use  go run :  go run myfirstworkflow.go",
            "title": "Run your workflow"
        },
        {
            "location": "/writing_workflows/",
            "text": "Writing workflows with SciPipe\n\n\nAn example workflow\n\n\nBefore going into details about how to write SciPipe workflows, let's look at\nthe example workflow used on the front page, and use it as an example when we\ndiscuss the SciPipe syntax further below:\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nsp\n \n\"github.com/scipipe/scipipe\"\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \n// Initialize processes\n\n    \nfooWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foowriter\"\n,\n \n\"echo 'foo' > {o:foo}\"\n)\n\n    \nfooToBar\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foo2bar\"\n,\n \n\"sed 's/foo/bar/g' {i:foo} > {o:bar}\"\n)\n\n    \nsink\n \n:=\n \nsp\n.\nNewSink\n()\n \n// Will just receive file targets, doing nothing\n\n\n    \n// Add output file path formatters for the components created above\n\n    \nfooWriter\n.\nSetPathStatic\n(\n\"foo\"\n,\n \n\"foo.txt\"\n)\n\n    \nfooToBar\n.\nSetPathExtend\n(\n\"foo\"\n,\n \n\"bar\"\n,\n \n\".bar\"\n)\n\n\n    \n// Connect network\n\n    \nfooToBar\n.\nIn\n[\n\"foo\"\n].\nConnect\n(\nfooWriter\n.\nOut\n[\n\"foo\"\n])\n\n    \nsink\n.\nConnect\n(\nfooToBar\n.\nOut\n[\n\"bar\"\n])\n\n\n    \n// Add to a pipeline runner and run\n\n    \npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n    \npipeline\n.\nAddProcesses\n(\nfooWriter\n,\n \nfooToBar\n,\n \nsink\n)\n\n    \npipeline\n.\nRun\n()\n\n\n}\n\n\n\n\n\n\nLet us now go through the code example step by step, and describe in more\ndetail what we are doing.\n\n\nInitializing processes\n\n\nfooWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foowriter\"\n,\n \n\"echo 'foo' > {o:out}\"\n)\n\n\nfooToBar\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foo2bar\"\n,\n \n\"sed 's/foo/bar/g' {i:foo} > {o:bar}\"\n)\n\n\nsink\n \n:=\n \nsp\n.\nNewSink\n()\n \n// Will just receive file targets, doing nothing\n\n\n\n\n\n\nFor these inports and outports, channels for sending and receiving FileTargets are automatically\ncreated and put in a hashmap added as a struct field of the process, named \nIn\n and \nOut\n repectively,\nEash channel is added to the hashmap with its inport/outport name as key in the hashmap,\nso that the channel can be retrieved from the hashmap using the in/outport name.\n\n\nConnecting processes into a network\n\n\nConnecting outports of one process to the inport of another process is then\ndone with the \nConnect\n method available on each port object. Sink objects have\na \nConnect\n method too:\n\n\nfooToBar\n.\nIn\n[\n\"foo\"\n].\nConnect\n(\nfooWriter\n.\nOut\n[\n\"foo\"\n])\n\n\nsink\n.\nConnect\n(\nfooToBar\n.\nOut\n[\n\"bar\"\n])\n\n\n\n\n\n\n(Note that the sink has just one inport, as a static struct field).\n\n\nFormatting output file paths\n\n\nThe only thing remaining after this, is to provide some way for the program to figure out a\nsuitable file name for each of the files propagating through this little \"network\" of processes.\nThis is done by adding a closure (function) to another special hashmap, again keyed by\nthe names of the outports of the processes. So, to define the output filenames of the two processes\nabove, we would add:\n\n\nfooWriter\n.\nPathFormatters\n[\n\"foo\"\n]\n \n=\n \nfunc\n(\nt\n \n*\nsp\n.\nSciTask\n)\n \nstring\n \n{\n\n    \n// Just statically create a file named foo.txt\n\n    \nreturn\n \n\"foo.txt\"\n\n\n}\n\n\nfooToBar\n.\nPathFormatters\n[\n\"bar\"\n]\n \n=\n \nfunc\n(\nt\n \n*\nsp\n.\nSciTask\n)\n \nstring\n \n{\n\n    \n// Here, we instead re-use the file name of the process we depend\n\n    \n// on (which we get on the 'foo' inport), and just\n\n    \n// pad '.bar' at the end:\n\n    \nreturn\n \nfooToBar\n.\nGetInPath\n(\n\"foo\"\n)\n \n+\n \n\".bar\"\n\n\n}\n\n\n\n\n\n\nFormatting output file paths: A nicer way\n\n\nNow, the above way of defining path formats is a bit verbose, isn't it?\nLuckily, there's a shorter way, by using convenience methods for doing the same\nthing. So, the above two path formats can also be defined like so, with the exact same result:\n\n\n// Create a static file name for the out-port 'foo':\n\n\nfooWriter\n.\nSetPathStatic\n(\n\"foo\"\n,\n \n\"foo.txt\"\n)\n\n\n\n// For out-port 'bar', extend the file names of files on in-port 'foo', with\n\n\n// the suffix '.bar':\n\n\nfooToBar\n.\nSetPathExtend\n(\n\"foo\"\n,\n \n\"bar\"\n,\n \n\".bar\"\n)\n\n\n\n\n\n\nRunning the pipeline\n\n\nSo, the final part probably explains itself, but the pipeline runner component\nis a very simple one that will start each component except the last one in a\nseparate go-routine, while the last process will be run in the main go-routine,\nso as to block until the pipeline has finished.\n\n\npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n\npipeline\n.\nAddProcesses\n(\nfooWriter\n,\n \nfooToBar\n,\n \nsink\n)\n\n\npipeline\n.\nRun\n()\n\n\n\n\n\n\nSummary\n\n\nSo with this, we have done everything needed to set up a file-based batch workflow system.\n\n\nIn summary, what we did, was to:\n\n\n\n\nSpecify process dependencies by wiring outputs of the upstream processes to inports in downstream processes.\n\n\nFor each outport, provide a function that will compute a suitable file name for the new file.\n\n\n\n\nFor more examples, see the \nexamples folder\n.",
            "title": "Writing Workflows"
        },
        {
            "location": "/writing_workflows/#writing-workflows-with-scipipe",
            "text": "",
            "title": "Writing workflows with SciPipe"
        },
        {
            "location": "/writing_workflows/#an-example-workflow",
            "text": "Before going into details about how to write SciPipe workflows, let's look at\nthe example workflow used on the front page, and use it as an example when we\ndiscuss the SciPipe syntax further below:  package   main  import   ( \n     sp   \"github.com/scipipe/scipipe\"  )  func   main ()   { \n     // Initialize processes \n     fooWriter   :=   sp . NewFromShell ( \"foowriter\" ,   \"echo 'foo' > {o:foo}\" ) \n     fooToBar   :=   sp . NewFromShell ( \"foo2bar\" ,   \"sed 's/foo/bar/g' {i:foo} > {o:bar}\" ) \n     sink   :=   sp . NewSink ()   // Will just receive file targets, doing nothing \n\n     // Add output file path formatters for the components created above \n     fooWriter . SetPathStatic ( \"foo\" ,   \"foo.txt\" ) \n     fooToBar . SetPathExtend ( \"foo\" ,   \"bar\" ,   \".bar\" ) \n\n     // Connect network \n     fooToBar . In [ \"foo\" ]. Connect ( fooWriter . Out [ \"foo\" ]) \n     sink . Connect ( fooToBar . Out [ \"bar\" ]) \n\n     // Add to a pipeline runner and run \n     pipeline   :=   sp . NewPipelineRunner () \n     pipeline . AddProcesses ( fooWriter ,   fooToBar ,   sink ) \n     pipeline . Run ()  }   Let us now go through the code example step by step, and describe in more\ndetail what we are doing.",
            "title": "An example workflow"
        },
        {
            "location": "/writing_workflows/#initializing-processes",
            "text": "fooWriter   :=   sp . NewFromShell ( \"foowriter\" ,   \"echo 'foo' > {o:out}\" )  fooToBar   :=   sp . NewFromShell ( \"foo2bar\" ,   \"sed 's/foo/bar/g' {i:foo} > {o:bar}\" )  sink   :=   sp . NewSink ()   // Will just receive file targets, doing nothing   For these inports and outports, channels for sending and receiving FileTargets are automatically\ncreated and put in a hashmap added as a struct field of the process, named  In  and  Out  repectively,\nEash channel is added to the hashmap with its inport/outport name as key in the hashmap,\nso that the channel can be retrieved from the hashmap using the in/outport name.",
            "title": "Initializing processes"
        },
        {
            "location": "/writing_workflows/#connecting-processes-into-a-network",
            "text": "Connecting outports of one process to the inport of another process is then\ndone with the  Connect  method available on each port object. Sink objects have\na  Connect  method too:  fooToBar . In [ \"foo\" ]. Connect ( fooWriter . Out [ \"foo\" ])  sink . Connect ( fooToBar . Out [ \"bar\" ])   (Note that the sink has just one inport, as a static struct field).",
            "title": "Connecting processes into a network"
        },
        {
            "location": "/writing_workflows/#formatting-output-file-paths",
            "text": "The only thing remaining after this, is to provide some way for the program to figure out a\nsuitable file name for each of the files propagating through this little \"network\" of processes.\nThis is done by adding a closure (function) to another special hashmap, again keyed by\nthe names of the outports of the processes. So, to define the output filenames of the two processes\nabove, we would add:  fooWriter . PathFormatters [ \"foo\" ]   =   func ( t   * sp . SciTask )   string   { \n     // Just statically create a file named foo.txt \n     return   \"foo.txt\"  }  fooToBar . PathFormatters [ \"bar\" ]   =   func ( t   * sp . SciTask )   string   { \n     // Here, we instead re-use the file name of the process we depend \n     // on (which we get on the 'foo' inport), and just \n     // pad '.bar' at the end: \n     return   fooToBar . GetInPath ( \"foo\" )   +   \".bar\"  }",
            "title": "Formatting output file paths"
        },
        {
            "location": "/writing_workflows/#formatting-output-file-paths-a-nicer-way",
            "text": "Now, the above way of defining path formats is a bit verbose, isn't it?\nLuckily, there's a shorter way, by using convenience methods for doing the same\nthing. So, the above two path formats can also be defined like so, with the exact same result:  // Create a static file name for the out-port 'foo':  fooWriter . SetPathStatic ( \"foo\" ,   \"foo.txt\" )  // For out-port 'bar', extend the file names of files on in-port 'foo', with  // the suffix '.bar':  fooToBar . SetPathExtend ( \"foo\" ,   \"bar\" ,   \".bar\" )",
            "title": "Formatting output file paths: A nicer way"
        },
        {
            "location": "/writing_workflows/#running-the-pipeline",
            "text": "So, the final part probably explains itself, but the pipeline runner component\nis a very simple one that will start each component except the last one in a\nseparate go-routine, while the last process will be run in the main go-routine,\nso as to block until the pipeline has finished.  pipeline   :=   sp . NewPipelineRunner ()  pipeline . AddProcesses ( fooWriter ,   fooToBar ,   sink )  pipeline . Run ()",
            "title": "Running the pipeline"
        },
        {
            "location": "/writing_workflows/#summary",
            "text": "So with this, we have done everything needed to set up a file-based batch workflow system.  In summary, what we did, was to:   Specify process dependencies by wiring outputs of the upstream processes to inports in downstream processes.  For each outport, provide a function that will compute a suitable file name for the new file.   For more examples, see the  examples folder .",
            "title": "Summary"
        },
        {
            "location": "/examples/",
            "text": "Examples\n\n\nSee the \nexamples folder\n in the main scipipe repository.",
            "title": "Examples"
        },
        {
            "location": "/examples/#examples",
            "text": "See the  examples folder  in the main scipipe repository.",
            "title": "Examples"
        }
    ]
}