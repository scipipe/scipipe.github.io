{
    "docs": [
        {
            "location": "/", 
            "text": "SciPipe\n\n\n\n\n\n\n\n\n\n\n\n\nProject links: \nGitHub repo\n | \nIssue Tracker\n | \nMailing List\n | \nChat\n\n\n\nSciPipe is a library for writing \nScientific\nWorkflows\n, sometimes\nalso called \"pipelines\", in the \nGo programming language\n.\n\n\nWhen you need to run many commandline programs that depend on each other in\ncomplex ways, SciPipe helps by making the process of running these programs\nflexible, robust and reproducible. SciPipe also lets you restart an interrupted\nrun without over-writing already produced output and produces an audit report\nof what was run, among many other things.\n\n\nSciPipe is built on the proven principles of \nFlow-Based\nProgramming\n (FBP) to\nachieve maximum flexibility, productivity and agility when designing workflows.\nSimilar to other FBP systems, SciPipe workflows can be likened to a network of\nassembly lines in a factory, where items (files) are flowing through a network\nof conveyor belts, stopping at different independently running stations\n(processes) for processing, as depicted in the picture above.\n\n\nSciPipe was initially created for problems in bioinformatics and\ncheminformatics, but works equally well for any problem involving pipelines of\ncommandline applications.\n\n\nBenefits\n\n\nSome key benefits of SciPipe, that are not always found in similar systems:\n\n\n\n\nIntuitive behaviour:\n SciPipe operates by flowing data (files) through a\n  network of channels and processes, not unlike the conveyor belts and stations\n  in a factory.\n\n\nFlexible:\n Processes that wrap command-line programs or scripts, can be\n  combined with processes coded directly in Golang.\n\n\nCustom file naming:\n SciPipe gives you full control over how files are\n  named, making it easy to find your way among the output files of your\n  workflow.\n\n\nPortable:\n Workflows can be distributed either as Go code to be run with\n  \ngo run\n, or as stand-alone executable files that run on almost any UNIX-like\n  operating system.\n\n\nEasy to debug:\n As everything in SciPipe is just Go code, you can use some\n  of the available debugging tools, or just \nprintln()\n statements, to debug\n  your workflow. \n\n\nSupports streaming:\n Can stream outputs via UNIX FIFO files, to avoid temporary storage.\n\n\nEfficient and Parallel:\n Workflows are compiled into statically compiled\n  code that runs fast. SciPipe also leverages pipeline parallelism between\n  processes as well as task parallelism when there are multiple inputs to a\n  process, making efficient use of multiple CPU cores.\n\n\n\n\nKnown limitations\n\n\n\n\nThere are still a number of missing good-to-have features for workflow\n  design. See the \nissue tracker\n\n  for details.\n\n\nThere is not (yet) support for the \nCommon Workflow Language\n.\n\n\n\n\nHello World example\n\n\nLet's look at an example workflow to get a feel for what writing workflows in\nSciPipe looks like:\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n        \n// Import SciPipe, aliased to \nsp\n for brevity\n\n        \nsp\n \ngithub.com/scipipe/scipipe\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n        \n// Initialize processes from shell command patterns\n\n        \nhelloWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\nhelloWriter\n,\n \necho \nHello \n \n {o:hellofile}\n)\n\n        \nworldAppender\n \n:=\n \nsp\n.\nNewFromShell\n(\nworldAppender\n,\n \necho $(cat {i:infile}) World \n {o:worldfile}\n)\n\n        \n// Create a sink, that will just receive the final outputs\n\n        \nsink\n \n:=\n \nsp\n.\nNewSink\n()\n\n\n        \n// Configure output file path formatters for the processes created above\n\n        \nhelloWriter\n.\nSetPathStatic\n(\nhellofile\n,\n \nhello.txt\n)\n\n        \nworldAppender\n.\nSetPathReplace\n(\ninfile\n,\n \nworldfile\n,\n \n.txt\n,\n \n_world.txt\n)\n\n\n        \n// Connect network\n\n        \nworldAppender\n.\nIn\n[\ninfile\n].\nConnect\n(\nhelloWriter\n.\nOut\n[\nhellofile\n])\n\n        \nsink\n.\nConnect\n(\nworldAppender\n.\nOut\n[\nworldfile\n])\n\n\n        \n// Create a pipeline runner, add processes, and run\n\n        \npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n        \npipeline\n.\nAddProcesses\n(\nhelloWriter\n,\n \nworldAppender\n,\n \nsink\n)\n\n        \npipeline\n.\nRun\n()\n\n\n}\n\n\n\n\n\n\nRunning the example\n\n\nLet's put the code in a file named \nscipipe_helloworld.go\n and run it:\n\n\n$ go run scipipe_helloworld.go \nAUDIT   \n2017\n/05/04 \n17\n:05:15 Task:helloWriter  Executing command: \necho\n \nHello \n \n hello.txt.tmp\nAUDIT   \n2017\n/05/04 \n17\n:05:15 Task:worldAppender Executing command: \necho\n \n$(\ncat hello.txt\n)\n World \n hello_world.txt.tmp\n\n\n\n\n\nLet's check what file SciPipe has generated:\n\n\n$ ls -1tr hello*\nhello.txt.audit.json\nhello.txt\nhello_world.txt\nhello_world.txt.audit.json\n\n\n\n\n\nAs you can see, it has created a file \nhello.txt\n, and \nhello_world.txt\n, and\nan accompanying \n.audit.json\n for each of these files.\n\n\nNow, let's check the output of the final resulting file:\n\n\n$ cat hello_world.txt\nHello World\n\n\n\n\n\nNow we can rejoice that it contains the text \"Hello World\", exactly as a proper\nHello World example should :)\n\n\nYou can find many more examples in the \nexamples folder\n in the GitHub repo.\n\n\nFor more information about how to write workflows using SciPipe, use the menu\nto the left, to browse the various topics!", 
            "title": "Introduction"
        }, 
        {
            "location": "/#scipipe", 
            "text": "Project links:  GitHub repo  |  Issue Tracker  |  Mailing List  |  Chat  \nSciPipe is a library for writing  Scientific\nWorkflows , sometimes\nalso called \"pipelines\", in the  Go programming language .  When you need to run many commandline programs that depend on each other in\ncomplex ways, SciPipe helps by making the process of running these programs\nflexible, robust and reproducible. SciPipe also lets you restart an interrupted\nrun without over-writing already produced output and produces an audit report\nof what was run, among many other things.  SciPipe is built on the proven principles of  Flow-Based\nProgramming  (FBP) to\nachieve maximum flexibility, productivity and agility when designing workflows.\nSimilar to other FBP systems, SciPipe workflows can be likened to a network of\nassembly lines in a factory, where items (files) are flowing through a network\nof conveyor belts, stopping at different independently running stations\n(processes) for processing, as depicted in the picture above.  SciPipe was initially created for problems in bioinformatics and\ncheminformatics, but works equally well for any problem involving pipelines of\ncommandline applications.", 
            "title": "SciPipe"
        }, 
        {
            "location": "/#benefits", 
            "text": "Some key benefits of SciPipe, that are not always found in similar systems:   Intuitive behaviour:  SciPipe operates by flowing data (files) through a\n  network of channels and processes, not unlike the conveyor belts and stations\n  in a factory.  Flexible:  Processes that wrap command-line programs or scripts, can be\n  combined with processes coded directly in Golang.  Custom file naming:  SciPipe gives you full control over how files are\n  named, making it easy to find your way among the output files of your\n  workflow.  Portable:  Workflows can be distributed either as Go code to be run with\n   go run , or as stand-alone executable files that run on almost any UNIX-like\n  operating system.  Easy to debug:  As everything in SciPipe is just Go code, you can use some\n  of the available debugging tools, or just  println()  statements, to debug\n  your workflow.   Supports streaming:  Can stream outputs via UNIX FIFO files, to avoid temporary storage.  Efficient and Parallel:  Workflows are compiled into statically compiled\n  code that runs fast. SciPipe also leverages pipeline parallelism between\n  processes as well as task parallelism when there are multiple inputs to a\n  process, making efficient use of multiple CPU cores.", 
            "title": "Benefits"
        }, 
        {
            "location": "/#known-limitations", 
            "text": "There are still a number of missing good-to-have features for workflow\n  design. See the  issue tracker \n  for details.  There is not (yet) support for the  Common Workflow Language .", 
            "title": "Known limitations"
        }, 
        {
            "location": "/#hello-world-example", 
            "text": "Let's look at an example workflow to get a feel for what writing workflows in\nSciPipe looks like:  package   main  import   ( \n         // Import SciPipe, aliased to  sp  for brevity \n         sp   github.com/scipipe/scipipe  )  func   main ()   { \n         // Initialize processes from shell command patterns \n         helloWriter   :=   sp . NewFromShell ( helloWriter ,   echo  Hello     {o:hellofile} ) \n         worldAppender   :=   sp . NewFromShell ( worldAppender ,   echo $(cat {i:infile}) World   {o:worldfile} ) \n         // Create a sink, that will just receive the final outputs \n         sink   :=   sp . NewSink () \n\n         // Configure output file path formatters for the processes created above \n         helloWriter . SetPathStatic ( hellofile ,   hello.txt ) \n         worldAppender . SetPathReplace ( infile ,   worldfile ,   .txt ,   _world.txt ) \n\n         // Connect network \n         worldAppender . In [ infile ]. Connect ( helloWriter . Out [ hellofile ]) \n         sink . Connect ( worldAppender . Out [ worldfile ]) \n\n         // Create a pipeline runner, add processes, and run \n         pipeline   :=   sp . NewPipelineRunner () \n         pipeline . AddProcesses ( helloWriter ,   worldAppender ,   sink ) \n         pipeline . Run ()  }", 
            "title": "Hello World example"
        }, 
        {
            "location": "/#running-the-example", 
            "text": "Let's put the code in a file named  scipipe_helloworld.go  and run it:  $ go run scipipe_helloworld.go \nAUDIT    2017 /05/04  17 :05:15 Task:helloWriter  Executing command:  echo   Hello     hello.txt.tmp\nAUDIT    2017 /05/04  17 :05:15 Task:worldAppender Executing command:  echo   $( cat hello.txt )  World   hello_world.txt.tmp  Let's check what file SciPipe has generated:  $ ls -1tr hello*\nhello.txt.audit.json\nhello.txt\nhello_world.txt\nhello_world.txt.audit.json  As you can see, it has created a file  hello.txt , and  hello_world.txt , and\nan accompanying  .audit.json  for each of these files.  Now, let's check the output of the final resulting file:  $ cat hello_world.txt\nHello World  Now we can rejoice that it contains the text \"Hello World\", exactly as a proper\nHello World example should :)  You can find many more examples in the  examples folder  in the GitHub repo.  For more information about how to write workflows using SciPipe, use the menu\nto the left, to browse the various topics!", 
            "title": "Running the example"
        }, 
        {
            "location": "/install/", 
            "text": "Installing SciPipe\n\n\nInstalling SciPipe means first installing the Go programming langauge, and then\nusing Go's \ngo get\n command to install the SciPipe library. After this, you will\nbe able to use Go's \ngo run\n command to run SciPipe workflows.\n\n\nInstall Go\n\n\nInstall Go by following the instructions \non this page\n,\nfor your operating system.\n\n\nInstall SciPipe\n\n\nThen install SciPipe by running the following shell command:\n\n\ngo get github.com/scipipe/scipipe/...\n\n\n\n\n\nN.B:\n Don't miss the \n...\n, as otherwise the \nscipipe\n helper tool will not be installed.\n\n\nInitialize a new workflow file\n\n\nNow, you should be able to write code like in the example below, in files ending with \n.go\n.\n\n\nThe easiest way to get started is to let the scipipe tool generate a starting point for you:\n\n\nscipipe new myfirstworkflow.go\n\n\n\n\n\n... which you can then edit to your liking.\n\n\nRun your workflow\n\n\nTo run a \n.go\n file, use \ngo run\n:\n\n\ngo run myfirstworkflow.go\n\n\n\n\n\nSome tips about editors\n\n\nIn order to be productive with SciPipe, you will also need a Go editor or IDE\nwith support for auto-completion, sometimes also called \"intellisense\".\n\n\nWe can warmly recommend to use one of these editors, sorted by level of endorsement:\n\n\n\n\nVisual Studio Code\n with the \nGo plugin\n - If you want a very powerful almost IDE-like editor\n\n\nFatih's awesome \nvim-go\n plugin - if you are a Vim power-user\n\n\nLiteIDE\n - if you want a really simple, standalone Go-editor\n\n\n\n\nThere are also popular Go-plugins for \nSublime text\n,\n\nAtom\n and \nIntelliJ IDEA\n,\nand an upcoming Go IDE from JetBrains, called\n\nGogland\n, that might be worth checking out,\ndepending on your preferences.", 
            "title": "Installing"
        }, 
        {
            "location": "/install/#installing-scipipe", 
            "text": "Installing SciPipe means first installing the Go programming langauge, and then\nusing Go's  go get  command to install the SciPipe library. After this, you will\nbe able to use Go's  go run  command to run SciPipe workflows.", 
            "title": "Installing SciPipe"
        }, 
        {
            "location": "/install/#install-go", 
            "text": "Install Go by following the instructions  on this page ,\nfor your operating system.", 
            "title": "Install Go"
        }, 
        {
            "location": "/install/#install-scipipe", 
            "text": "Then install SciPipe by running the following shell command:  go get github.com/scipipe/scipipe/...  N.B:  Don't miss the  ... , as otherwise the  scipipe  helper tool will not be installed.", 
            "title": "Install SciPipe"
        }, 
        {
            "location": "/install/#initialize-a-new-workflow-file", 
            "text": "Now, you should be able to write code like in the example below, in files ending with  .go .  The easiest way to get started is to let the scipipe tool generate a starting point for you:  scipipe new myfirstworkflow.go  ... which you can then edit to your liking.", 
            "title": "Initialize a new workflow file"
        }, 
        {
            "location": "/install/#run-your-workflow", 
            "text": "To run a  .go  file, use  go run :  go run myfirstworkflow.go", 
            "title": "Run your workflow"
        }, 
        {
            "location": "/install/#some-tips-about-editors", 
            "text": "In order to be productive with SciPipe, you will also need a Go editor or IDE\nwith support for auto-completion, sometimes also called \"intellisense\".  We can warmly recommend to use one of these editors, sorted by level of endorsement:   Visual Studio Code  with the  Go plugin  - If you want a very powerful almost IDE-like editor  Fatih's awesome  vim-go  plugin - if you are a Vim power-user  LiteIDE  - if you want a really simple, standalone Go-editor   There are also popular Go-plugins for  Sublime text , Atom  and  IntelliJ IDEA ,\nand an upcoming Go IDE from JetBrains, called Gogland , that might be worth checking out,\ndepending on your preferences.", 
            "title": "Some tips about editors"
        }, 
        {
            "location": "/basic_concepts/", 
            "text": "Basic concepts\n\n\nIn SciLuigi, we are discussing a few concepts all the time, so to make sure we\nare on the same page, we will below go through the basic ones briefly.\n\n\nProcesses\n\n\nThe probably most basic concept in SciPipe is the process.  A process is an\nasynchronously running component that is typically defined as a static,\n\"long-running\" part of the workflow, and the number of processes thus is\ntypically fixed for a workflow during its execution.\n\n\nOne can create customized types of processes, but for most basic workflows, the\n\nscipipe.SciProcess\n\nwill be used, which is specialized for executing commandline applications. New\n\nSciProcess\n-es are typically created using the \nscipipe.NewFromShell(procName,\nshellPattern)\n command.\n\n\n\n\nSee \nGoDoc for SciProcess\n\n\n\n\nTasks\n\n\nThe \"long-running\" processes mentioned above, will receive input files on its\nin-ports, and for each complete set of input files it receives, it will create\na new \ntask\n. Specifically, \nscipipe.SciProcess\n will create\n\nscipipe.SciTask\n objects, and populate it with all data needed for one\nparticular shell command execution.  \nSciTask\n objects are executed via their\n\nExecute()\n\nmethod, or \nCustomExecute()\n, if custom Go code is supposed to be\nexecuted instead of a shell command.\n\n\nThe distinction between processes and tasks is important to understand, for\nexample when doing more advanced configuration of file naming strategies, since\nthe custom anonymous functions used to format paths are taking a \nSciTask\n as\ninput, even though these functions are saved on the process object.\n\n\nTo understand the difference between processes and tasks, it is helpful to\nremember that processes are long-running, and typically fixed during the course\nof a workflow, while tasks are transient objects, created temporarily as a\ncontainer for all data and code needed for each execution of a concrete shell\ncommand.\n\n\n\n\nSee \nGoDoc for SciTask\n\n\n\n\nPorts\n\n\nCentral to the way data dependencies are defined in SciPipe, is ports. Ports\nare fields on processes, which are connected to other ports via channels (see\nseparate section on this page).\n\n\nIn SciPipe, each port must have a unique name within its process (there can't\nbe an in-port and out-port named the same), and this name will be used in shell\ncommand patterns, when connecting dependencies / dataflow networks, and when\nconfiguring file naming strategies.\n\n\nIn \nSciProcess\n objects, in-ports are stored in a string-\nPort map field named\n\nIn\n (so they are accessed with: \nmyProcess.In[\"myport\"]\n), and out-ports\nsimilarly in a string-\nPort map field named \nOut\n. Both are of type \nFilePort\n.\n\n\nSome pre-made components might have ports bound to custom field names though,\nsuch as \nmyFastaReader.InFastaFile\n, or \nmyZipComponent.OutZipFile\n.\n\n\nPort objects have some methods bound to them, most importantly the \nConnect()\n\nmethod, which takes another port, and connects to it, by stitching a channel\nbetween the ports.\n\n\nOn \nSciProcess\n objects, there is also a third port type, \nParamPorts\n, which\nis used when it is needed to send a stream of parameter values (in string\nformat) to be supplied to as arguments to shell commands.\n\n\n\n\nSee \nGoDoc for the Port interface\n\n\nSee \nGoDoc for the FilePort struct type\n\n\nSee \nGoDoc for the ParamPort struct type\n\n\n\n\nChannels\n\n\nPorts in SciPipe are connected via channels. Channels are \nplain Go channels\n\nand nothing more. Most of the time, one will not need to deal with the channels\ndirectly though, since the port objects (see separate section for ports) have\nall the logic to connect to other ports via channels, but it can be good to\nknow that they are there, in case you need to do something more advanced.\n\n\nPipeline runner\n\n\nThe \nPipelineRunner\n\nis a special object in SciPipe, that just takes care of running a pipeline of\ncomponents. \n\n\nThere is not much to say about the pipeline runner other than that it is\ncreated with \nscipipe.NewPipelineRunner()\n, that all processes need to be added\nto it in the right order (the last process last) with\n\nrunner.AddProcesses(processes...)\n and that it should be run with\n\nrunner.Run()\n. But this is already covered in the other examples and\ntutorials.\n\n\n\n\nSee \nGoDoc for PipelineRunner\n\n\n\n\nShell command pattern\n\n\nThe \nSciProcess\n has the speciality that it can be configured using a special\nshell command pattern, supplied to the \nNewFromShell()\n\nfactory function. It is already explained in the section \"writing workflows\",\nbut in brief, it is a normal shell command, with placeholders for in-ports,\nout-ports and parameter ports, on the form \n{i:inportname}\n, \n{o:outportname}\n,\nand \n{p:paramportname}\n, respectively.\n\n\n\n\nSee \nGoDoc for NewFromShell()", 
            "title": "Basic Concepts"
        }, 
        {
            "location": "/basic_concepts/#basic-concepts", 
            "text": "In SciLuigi, we are discussing a few concepts all the time, so to make sure we\nare on the same page, we will below go through the basic ones briefly.", 
            "title": "Basic concepts"
        }, 
        {
            "location": "/basic_concepts/#processes", 
            "text": "The probably most basic concept in SciPipe is the process.  A process is an\nasynchronously running component that is typically defined as a static,\n\"long-running\" part of the workflow, and the number of processes thus is\ntypically fixed for a workflow during its execution.  One can create customized types of processes, but for most basic workflows, the scipipe.SciProcess \nwill be used, which is specialized for executing commandline applications. New SciProcess -es are typically created using the  scipipe.NewFromShell(procName,\nshellPattern)  command.   See  GoDoc for SciProcess", 
            "title": "Processes"
        }, 
        {
            "location": "/basic_concepts/#tasks", 
            "text": "The \"long-running\" processes mentioned above, will receive input files on its\nin-ports, and for each complete set of input files it receives, it will create\na new  task . Specifically,  scipipe.SciProcess  will create scipipe.SciTask  objects, and populate it with all data needed for one\nparticular shell command execution.   SciTask  objects are executed via their Execute() \nmethod, or  CustomExecute() , if custom Go code is supposed to be\nexecuted instead of a shell command.  The distinction between processes and tasks is important to understand, for\nexample when doing more advanced configuration of file naming strategies, since\nthe custom anonymous functions used to format paths are taking a  SciTask  as\ninput, even though these functions are saved on the process object.  To understand the difference between processes and tasks, it is helpful to\nremember that processes are long-running, and typically fixed during the course\nof a workflow, while tasks are transient objects, created temporarily as a\ncontainer for all data and code needed for each execution of a concrete shell\ncommand.   See  GoDoc for SciTask", 
            "title": "Tasks"
        }, 
        {
            "location": "/basic_concepts/#ports", 
            "text": "Central to the way data dependencies are defined in SciPipe, is ports. Ports\nare fields on processes, which are connected to other ports via channels (see\nseparate section on this page).  In SciPipe, each port must have a unique name within its process (there can't\nbe an in-port and out-port named the same), and this name will be used in shell\ncommand patterns, when connecting dependencies / dataflow networks, and when\nconfiguring file naming strategies.  In  SciProcess  objects, in-ports are stored in a string- Port map field named In  (so they are accessed with:  myProcess.In[\"myport\"] ), and out-ports\nsimilarly in a string- Port map field named  Out . Both are of type  FilePort .  Some pre-made components might have ports bound to custom field names though,\nsuch as  myFastaReader.InFastaFile , or  myZipComponent.OutZipFile .  Port objects have some methods bound to them, most importantly the  Connect() \nmethod, which takes another port, and connects to it, by stitching a channel\nbetween the ports.  On  SciProcess  objects, there is also a third port type,  ParamPorts , which\nis used when it is needed to send a stream of parameter values (in string\nformat) to be supplied to as arguments to shell commands.   See  GoDoc for the Port interface  See  GoDoc for the FilePort struct type  See  GoDoc for the ParamPort struct type", 
            "title": "Ports"
        }, 
        {
            "location": "/basic_concepts/#channels", 
            "text": "Ports in SciPipe are connected via channels. Channels are  plain Go channels \nand nothing more. Most of the time, one will not need to deal with the channels\ndirectly though, since the port objects (see separate section for ports) have\nall the logic to connect to other ports via channels, but it can be good to\nknow that they are there, in case you need to do something more advanced.", 
            "title": "Channels"
        }, 
        {
            "location": "/basic_concepts/#pipeline-runner", 
            "text": "The  PipelineRunner \nis a special object in SciPipe, that just takes care of running a pipeline of\ncomponents.   There is not much to say about the pipeline runner other than that it is\ncreated with  scipipe.NewPipelineRunner() , that all processes need to be added\nto it in the right order (the last process last) with runner.AddProcesses(processes...)  and that it should be run with runner.Run() . But this is already covered in the other examples and\ntutorials.   See  GoDoc for PipelineRunner", 
            "title": "Pipeline runner"
        }, 
        {
            "location": "/basic_concepts/#shell-command-pattern", 
            "text": "The  SciProcess  has the speciality that it can be configured using a special\nshell command pattern, supplied to the  NewFromShell() \nfactory function. It is already explained in the section \"writing workflows\",\nbut in brief, it is a normal shell command, with placeholders for in-ports,\nout-ports and parameter ports, on the form  {i:inportname} ,  {o:outportname} ,\nand  {p:paramportname} , respectively.   See  GoDoc for NewFromShell()", 
            "title": "Shell command pattern"
        }, 
        {
            "location": "/writing_workflows/", 
            "text": "Writing Workflows - An Overview\n\n\nIn order to give an overview of how to write workflows in SciPipe, let's look\nat the example workflow used on the front page again:\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \n// Import SciPipe, aliased to \nsp\n for brevity\n\n    \nsp\n \ngithub.com/scipipe/scipipe\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \n// Initialize processes from shell command patterns\n\n    \nhelloWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\nhelloWriter\n,\n \necho \nHello \n \n {o:hellofile}\n)\n\n    \nworldAppender\n \n:=\n \nsp\n.\nNewFromShell\n(\nworldAppender\n,\n \necho $(cat {i:infile}) World \n {o:worldfile}\n)\n\n    \n// Create a sink, that will just receive the final outputs\n\n    \nsink\n \n:=\n \nsp\n.\nNewSink\n()\n\n\n    \n// Configure output file path formatters for the processes created above\n\n    \nhelloWriter\n.\nSetPathStatic\n(\nhellofile\n,\n \nhello.txt\n)\n\n    \nworldAppender\n.\nSetPathReplace\n(\ninfile\n,\n \nworldfile\n,\n \n.txt\n,\n \n_world.txt\n)\n\n\n    \n// Connect network\n\n    \nworldAppender\n.\nIn\n[\ninfile\n].\nConnect\n(\nhelloWriter\n.\nOut\n[\nhellofile\n])\n\n    \nsink\n.\nConnect\n(\nworldAppender\n.\nOut\n[\nworldfile\n])\n\n\n    \n// Create a pipeline runner, add processes, and run\n\n    \npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n    \npipeline\n.\nAddProcesses\n(\nhelloWriter\n,\n \nworldAppender\n,\n \nsink\n)\n\n    \npipeline\n.\nRun\n()\n\n\n}\n\n\n\n\n\n\nNow let's go through the code example in some detail, to see what we are\nactually doing.\n\n\nInitializing processes\n\n\n// Initialize processes from shell command patterns\n\n\nhelloWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\nhelloWriter\n,\n \necho \nHello \n \n {o:hellofile}\n)\n\n\nworldAppender\n \n:=\n \nsp\n.\nNewFromShell\n(\nworldAppender\n,\n \necho $(cat {i:infile}) World \n {o:worldfile}\n)\n\n\n// Create a sink, that will just receive the final outputs\n\n\nsink\n \n:=\n \nsp\n.\nNewSink\n()\n\n\n\n\n\n\nHere we are initializing three new processes, two of them based on a shell\ncommand, and one \"sink\", which will just receive inputs adn nothing more.\n\n\nThe two first processes are created using the \nscipipe.NewFromShell()\n\nfunction, which takes a processname, and a shell command pattern as input.\n\n\nThe shell command pattern\n\n\nThe shell command patterns, in this case \necho 'Hello ' \n {o:hellofile}\n and\n\necho $(cat {i:infile}) World \n {o:worldfile}\n, are basically normal bash\nshell commands, with the addition of \"placeholders\" for input and output\nfilenames.\n\n\nInput filename placeholders are on the form \n{i:INPORT-NAME}\n and the output\nfilename placeholders are similarly of the form \n{o:OUTPORT-NAME}\n.  These\nplaceholders will be replaced with actual filenames when the command is\nexecuted later. The reason that it a port-name is used to name them, is that\nfiles will be queued on the channel connecting to the port, and for each set of\nfiles on in-ports, a command will be created and executed whereafter new files\nwill be pulled in on the out-ports, and so on.\n\n\nThe sink\n\n\nThe sink is needed in cases where the workflow ends with a process that is not\nan explicit endpoint without out-ports, such as a \"printer\" processes or\nsimilar, but instead has out-ports that need to be connected. Then the sink can\nbe used to receive from these out-ports so that the data packets on the\nout-ports don't get stuck and clog the workflow.\n\n\nFor these inports and outports, channels for sending and receiving FileTargets\nare automatically created and put in a hashmap added as a struct field of the\nprocess, named \nIn\n and \nOut\n repectively, Eash channel is added to the hashmap\nwith its inport/outport name as key in the hashmap, so that the channel can be\nretrieved from the hashmap using the in/outport name.\n\n\nFormatting output file paths\n\n\nNow we need to provide some way for scipipe to figure out a suitable file name\nfor each of the files propagating through the \"network\" of processes.  This can\nbe done using special convenience methods on the processes, starting with\n\nSetPath...\n. There are a few variants, of which two of them are shown here.\n\n\n// Configure output file path formatters for the processes created above\n\n\nhelloWriter\n.\nSetPathStatic\n(\nhellofile\n,\n \nhello.txt\n)\n\n\nworldAppender\n.\nSetPathReplace\n(\ninfile\n,\n \nworldfile\n,\n \n.txt\n,\n \n_world.txt\n)\n\n\n\n\n\n\nSetPathStatic\n just takes an out-port name and a static file name to use, and\nis suitable for processes which produce only one single output for a whole\nworkflow run.\n\n\nSetPathReplace\n is slightly more advanced: It takes an in-port name, and\nout-port name, and then a search-pattern in the input-filename, and a\nreplace-pattern for the output filename.  With the example above, our input\nfile named \nhello.txt\n will be converted into \nhello_world.txt\n by this path\npattern.\n\n\nEven more control over file formatting\n\n\nWe can actually get even more control over how file names are produced than\nthis, by manually supplying each process with an anonymous function that\nreturns file paths given a \nscipipe.SciTask\n object, which will be produced for\neach command execution.\n\n\nIn order to implement the same path patterns as above, using this method, we\nwould write like this: \n\n\n// Configure output file path formatters for the processes created above\n\n\nhelloWriter\n.\nPathFormatters\n[\nhellofile\n]\n \n=\n \nfunc\n(\nt\n \n*\nsp\n.\nSciTask\n)\n \nstring\n \n{\n\n\nreturn\n \nhello.txt\n\n\n}\n\n\nworldAppender\n.\nPathFormatters\n[\nworldfile\n]\n \n=\n \nfunc\n(\nt\n \n*\nsp\n.\nSciTask\n)\n \nstring\n \n{\n\n\nreturn\n \nstrings\n.\nReplace\n(\nt\n.\nInTargets\n[\ninfile\n].\nGetPath\n(),\n \n.txt\n,\n \n_world.txt\n,\n \n-\n1\n)\n\n\n}\n\n\n\n\n\n\nAs you can see, this is a much more complicated way to format paths, but it can\nbe useful for example when needing to incorporate parameter values into file\nnames.\n\n\nConnecting processes into a network\n\n\nFinally we need to define the data dependencies between our processes.  We do\nthis by connecting the outports of one process to the inport of another\nprocess, using the \nConnect\n method available on each port object. Sink objects\nhave a \nConnect\n method too, which take an out-port of an upstream process:\n\n\n// Connect network\n\n\nworldAppender\n.\nIn\n[\ninfile\n].\nConnect\n(\nhelloWriter\n.\nOut\n[\nhellofile\n])\n\n\nsink\n.\nConnect\n(\nworldAppender\n.\nOut\n[\nworldfile\n])\n\n\n\n\n\n\n(Note that the sink has the \nConnect\n method bound directly to itself, without\nany port).\n\n\nRunning the pipeline\n\n\nSo, the final part probably explains itself, but the pipeline runner component\nis a very simple one that will start each component except the last one in a\nseparate go-routine, while the last process will be run in the main go-routine,\nso as to block until the pipeline has finished.\n\n\n// Create a pipeline runner, add processes, and run\n\n\npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n\npipeline\n.\nAddProcesses\n(\nhelloWriter\n,\n \nworldAppender\n,\n \nsink\n)\n\n\npipeline\n.\nRun\n()\n\n\n\n\n\n\nSummary\n\n\nSo with this, we have done everything needed to set up a file-based batch workflow system.\n\n\nIn summary, what we did, was to:\n\n\n\n\nInitialize processes\n\n\nFor each out-port, define a file-naming strategy\n\n\nSpecify dependencies by connecting out- and in-ports\n\n\nRun the pipeline\n\n\n\n\nThis actually turns out to be a fixed set of components that always need to be\nincluded when writing workflows, so it might be good to keep them in mind and\nmemorize these steps, if needed.\n\n\nFor more examples, see the \nexamples folder\n\nin the GitHub repository.", 
            "title": "Writing Workflows"
        }, 
        {
            "location": "/writing_workflows/#writing-workflows-an-overview", 
            "text": "In order to give an overview of how to write workflows in SciPipe, let's look\nat the example workflow used on the front page again:  package   main  import   ( \n     // Import SciPipe, aliased to  sp  for brevity \n     sp   github.com/scipipe/scipipe  )  func   main ()   { \n     // Initialize processes from shell command patterns \n     helloWriter   :=   sp . NewFromShell ( helloWriter ,   echo  Hello     {o:hellofile} ) \n     worldAppender   :=   sp . NewFromShell ( worldAppender ,   echo $(cat {i:infile}) World   {o:worldfile} ) \n     // Create a sink, that will just receive the final outputs \n     sink   :=   sp . NewSink () \n\n     // Configure output file path formatters for the processes created above \n     helloWriter . SetPathStatic ( hellofile ,   hello.txt ) \n     worldAppender . SetPathReplace ( infile ,   worldfile ,   .txt ,   _world.txt ) \n\n     // Connect network \n     worldAppender . In [ infile ]. Connect ( helloWriter . Out [ hellofile ]) \n     sink . Connect ( worldAppender . Out [ worldfile ]) \n\n     // Create a pipeline runner, add processes, and run \n     pipeline   :=   sp . NewPipelineRunner () \n     pipeline . AddProcesses ( helloWriter ,   worldAppender ,   sink ) \n     pipeline . Run ()  }   Now let's go through the code example in some detail, to see what we are\nactually doing.", 
            "title": "Writing Workflows - An Overview"
        }, 
        {
            "location": "/writing_workflows/#initializing-processes", 
            "text": "// Initialize processes from shell command patterns  helloWriter   :=   sp . NewFromShell ( helloWriter ,   echo  Hello     {o:hellofile} )  worldAppender   :=   sp . NewFromShell ( worldAppender ,   echo $(cat {i:infile}) World   {o:worldfile} )  // Create a sink, that will just receive the final outputs  sink   :=   sp . NewSink ()   Here we are initializing three new processes, two of them based on a shell\ncommand, and one \"sink\", which will just receive inputs adn nothing more.  The two first processes are created using the  scipipe.NewFromShell() \nfunction, which takes a processname, and a shell command pattern as input.", 
            "title": "Initializing processes"
        }, 
        {
            "location": "/writing_workflows/#the-shell-command-pattern", 
            "text": "The shell command patterns, in this case  echo 'Hello '   {o:hellofile}  and echo $(cat {i:infile}) World   {o:worldfile} , are basically normal bash\nshell commands, with the addition of \"placeholders\" for input and output\nfilenames.  Input filename placeholders are on the form  {i:INPORT-NAME}  and the output\nfilename placeholders are similarly of the form  {o:OUTPORT-NAME} .  These\nplaceholders will be replaced with actual filenames when the command is\nexecuted later. The reason that it a port-name is used to name them, is that\nfiles will be queued on the channel connecting to the port, and for each set of\nfiles on in-ports, a command will be created and executed whereafter new files\nwill be pulled in on the out-ports, and so on.", 
            "title": "The shell command pattern"
        }, 
        {
            "location": "/writing_workflows/#the-sink", 
            "text": "The sink is needed in cases where the workflow ends with a process that is not\nan explicit endpoint without out-ports, such as a \"printer\" processes or\nsimilar, but instead has out-ports that need to be connected. Then the sink can\nbe used to receive from these out-ports so that the data packets on the\nout-ports don't get stuck and clog the workflow.  For these inports and outports, channels for sending and receiving FileTargets\nare automatically created and put in a hashmap added as a struct field of the\nprocess, named  In  and  Out  repectively, Eash channel is added to the hashmap\nwith its inport/outport name as key in the hashmap, so that the channel can be\nretrieved from the hashmap using the in/outport name.", 
            "title": "The sink"
        }, 
        {
            "location": "/writing_workflows/#formatting-output-file-paths", 
            "text": "Now we need to provide some way for scipipe to figure out a suitable file name\nfor each of the files propagating through the \"network\" of processes.  This can\nbe done using special convenience methods on the processes, starting with SetPath... . There are a few variants, of which two of them are shown here.  // Configure output file path formatters for the processes created above  helloWriter . SetPathStatic ( hellofile ,   hello.txt )  worldAppender . SetPathReplace ( infile ,   worldfile ,   .txt ,   _world.txt )   SetPathStatic  just takes an out-port name and a static file name to use, and\nis suitable for processes which produce only one single output for a whole\nworkflow run.  SetPathReplace  is slightly more advanced: It takes an in-port name, and\nout-port name, and then a search-pattern in the input-filename, and a\nreplace-pattern for the output filename.  With the example above, our input\nfile named  hello.txt  will be converted into  hello_world.txt  by this path\npattern.", 
            "title": "Formatting output file paths"
        }, 
        {
            "location": "/writing_workflows/#even-more-control-over-file-formatting", 
            "text": "We can actually get even more control over how file names are produced than\nthis, by manually supplying each process with an anonymous function that\nreturns file paths given a  scipipe.SciTask  object, which will be produced for\neach command execution.  In order to implement the same path patterns as above, using this method, we\nwould write like this:   // Configure output file path formatters for the processes created above  helloWriter . PathFormatters [ hellofile ]   =   func ( t   * sp . SciTask )   string   {  return   hello.txt  }  worldAppender . PathFormatters [ worldfile ]   =   func ( t   * sp . SciTask )   string   {  return   strings . Replace ( t . InTargets [ infile ]. GetPath (),   .txt ,   _world.txt ,   - 1 )  }   As you can see, this is a much more complicated way to format paths, but it can\nbe useful for example when needing to incorporate parameter values into file\nnames.", 
            "title": "Even more control over file formatting"
        }, 
        {
            "location": "/writing_workflows/#connecting-processes-into-a-network", 
            "text": "Finally we need to define the data dependencies between our processes.  We do\nthis by connecting the outports of one process to the inport of another\nprocess, using the  Connect  method available on each port object. Sink objects\nhave a  Connect  method too, which take an out-port of an upstream process:  // Connect network  worldAppender . In [ infile ]. Connect ( helloWriter . Out [ hellofile ])  sink . Connect ( worldAppender . Out [ worldfile ])   (Note that the sink has the  Connect  method bound directly to itself, without\nany port).", 
            "title": "Connecting processes into a network"
        }, 
        {
            "location": "/writing_workflows/#running-the-pipeline", 
            "text": "So, the final part probably explains itself, but the pipeline runner component\nis a very simple one that will start each component except the last one in a\nseparate go-routine, while the last process will be run in the main go-routine,\nso as to block until the pipeline has finished.  // Create a pipeline runner, add processes, and run  pipeline   :=   sp . NewPipelineRunner ()  pipeline . AddProcesses ( helloWriter ,   worldAppender ,   sink )  pipeline . Run ()", 
            "title": "Running the pipeline"
        }, 
        {
            "location": "/writing_workflows/#summary", 
            "text": "So with this, we have done everything needed to set up a file-based batch workflow system.  In summary, what we did, was to:   Initialize processes  For each out-port, define a file-naming strategy  Specify dependencies by connecting out- and in-ports  Run the pipeline   This actually turns out to be a fixed set of components that always need to be\nincluded when writing workflows, so it might be good to keep them in mind and\nmemorize these steps, if needed.  For more examples, see the  examples folder \nin the GitHub repository.", 
            "title": "Summary"
        }, 
        {
            "location": "/examples/", 
            "text": "Examples\n\n\nWe plan to go through a few examples in more depth here soon, but in the\nmeanwhile, see the \nexamples folder\n\nin the main scipipe repository, for a bunch of examples spanning much of the\nfunctionality in SciPipe.", 
            "title": "Examples"
        }, 
        {
            "location": "/examples/#examples", 
            "text": "We plan to go through a few examples in more depth here soon, but in the\nmeanwhile, see the  examples folder \nin the main scipipe repository, for a bunch of examples spanning much of the\nfunctionality in SciPipe.", 
            "title": "Examples"
        }, 
        {
            "location": "/other_resources/", 
            "text": "Publications mentioning SciPipe\n\n\n\n\nSee \na poster on SciPipe\n, presented at the \ne-Science Academy in Lund, on Oct 12-13 2016\n.\n\n\nSee \nslides from a recent presentation of SciPipe for use in a Bioinformatics setting\n.\n\n\nThe architecture of SciPipe is based on an \nflow-based\n  programming\n like\n  pattern in pure Go presented in\n  \nthis\n and\n  \nthis\n\n  blog posts on Gopher Academy.", 
            "title": "Other Resources"
        }, 
        {
            "location": "/other_resources/#publications-mentioning-scipipe", 
            "text": "See  a poster on SciPipe , presented at the  e-Science Academy in Lund, on Oct 12-13 2016 .  See  slides from a recent presentation of SciPipe for use in a Bioinformatics setting .  The architecture of SciPipe is based on an  flow-based\n  programming  like\n  pattern in pure Go presented in\n   this  and\n   this \n  blog posts on Gopher Academy.", 
            "title": "Publications mentioning SciPipe"
        }, 
        {
            "location": "/acknowledgements/", 
            "text": "Acknowledgements\n\n\n\n\nSciPipe is very heavily dependent on the proven principles form \nFlow-Based\n  Programming (FBP)\n, as invented by \nJohn Paul Morrison\n.\n  From Flow-based programming, SciPipe uses the ideas of separate network\n  (workflow dependency graph) definition, named in- and out-ports,\n  sub-networks/sub-workflows and bounded buffers (already available in Go's\n  channels) to make writing workflows as easy as possible.\n\n\nThis library is has been much influenced/inspired also by the\n  \nGoFlow\n library by \nVladimir Sibirov\n.\n\n\nThanks to \nEgon Elbre\n for helpful input on the\n  design of the internals of the pipeline, and processes, which greatly\n  simplified the implementation.\n\n\nThis work is financed by faculty grants and other financing for the \nPharmaceutical Bioinformatics group\n of \nDept. of\n  Pharmaceutical Biosciences\n at \nUppsala University\n, and by \nSwedish Research Council\n\n  through the Swedish \nNational Bioinformatics Infrastructure Sweden\n.\n\n\nSupervisor for the project is \nOla Spjuth\n.", 
            "title": "Acknowledgements"
        }, 
        {
            "location": "/acknowledgements/#acknowledgements", 
            "text": "SciPipe is very heavily dependent on the proven principles form  Flow-Based\n  Programming (FBP) , as invented by  John Paul Morrison .\n  From Flow-based programming, SciPipe uses the ideas of separate network\n  (workflow dependency graph) definition, named in- and out-ports,\n  sub-networks/sub-workflows and bounded buffers (already available in Go's\n  channels) to make writing workflows as easy as possible.  This library is has been much influenced/inspired also by the\n   GoFlow  library by  Vladimir Sibirov .  Thanks to  Egon Elbre  for helpful input on the\n  design of the internals of the pipeline, and processes, which greatly\n  simplified the implementation.  This work is financed by faculty grants and other financing for the  Pharmaceutical Bioinformatics group  of  Dept. of\n  Pharmaceutical Biosciences  at  Uppsala University , and by  Swedish Research Council \n  through the Swedish  National Bioinformatics Infrastructure Sweden .  Supervisor for the project is  Ola Spjuth .", 
            "title": "Acknowledgements"
        }, 
        {
            "location": "/related_tools/", 
            "text": "Related tools\n\n\nFind below a few tools that are more or less similar to SciPipe that are worth worth checking out before\ndeciding on what tool fits you best (in approximate order of similarity to SciPipe):\n\n\n\n\nNextFlow\n\n\nLuigi\n/\nSciLuigi\n\n\nBPipe\n\n\nSnakeMake\n\n\nCuneiform", 
            "title": "Related Tools"
        }, 
        {
            "location": "/related_tools/#related-tools", 
            "text": "Find below a few tools that are more or less similar to SciPipe that are worth worth checking out before\ndeciding on what tool fits you best (in approximate order of similarity to SciPipe):   NextFlow  Luigi / SciLuigi  BPipe  SnakeMake  Cuneiform", 
            "title": "Related tools"
        }
    ]
}