{
    "docs": [
        {
            "location": "/", 
            "text": "SciPipe\n\n\n\n\n\n\n\n\n\n\nProject links: \nGitHub Repo\n | \nIssue Tracker\n | \nMailing List\n\n\n\nSciPipe is a library for writing \nScientific\nWorkflows\n, sometimes\nalso called \"pipelines\", in the \nGo programming language\n.\n\n\nWhen you need to run many commandline programs that depend on each other in\ncomplex ways, SciPipe helps by making the process of running these programs\nflexible, robust and reproducible. SciPipe also lets you restart an interrupted\nrun without over-writing already produced output and produces an audit report\nof what was run, among many other things.\n\n\nSciPipe is built on the proven principles of \nFlow-Based\nProgramming\n (FBP) to\nachieve maximum flexibility, productivity and agility when designing workflows.\nSimilar to other FBP systems, SciPipe workflows can be likened to a network of\nassembly lines in a factory, where items (files) are flowing through a network\nof conveyor belts, stopping at different independently running stations\n(processes) for processing, as depicted in the picture above.\n\n\nSciPipe was initially created for problems in bioinformatics and\ncheminformatics, but works equally well for any problem involving pipelines of\ncommandline applications.\n\n\nBenefits\n\n\nSome key benefits of SciPipe, that are not always found in similar systems:\n\n\n\n\nIntuitive behaviour:\n SciPipe operates by flowing data (files) through a\n  network of channels and processes, not unlike the conveyor belts and stations\n  in a factory.\n\n\nFlexible:\n Processes that wrap command-line programs or scripts, can be\n  combined with processes coded directly in Golang.\n\n\nCustom file naming:\n SciPipe gives you full control over how files are\n  named, making it easy to find your way among the output files of your\n  workflow.\n\n\nPortable:\n Workflows can be distributed either as Go code to be run with\n  \ngo run\n, or as stand-alone executable files that run on almost any UNIX-like\n  operating system.\n\n\nEasy to debug:\n As everything in SciPipe is just Go code, you can use some\n  of the available debugging tools, or just \nprintln()\n statements, to debug\n  your workflow. \n\n\nSupports streaming:\n Can stream outputs via UNIX FIFO files, to avoid temporary storage.\n\n\nEfficient and Parallel:\n Workflows are compiled into statically compiled\n  code that runs fast. SciPipe also leverages pipeline parallelism between\n  processes as well as task parallelism when there are multiple inputs to a\n  process, making efficient use of multiple CPU cores.\n\n\n\n\nKnown limitations\n\n\n\n\nThere are still a number of missing good-to-have features for workflow\n  design. See the \nissue tracker\n\n  for details.\n\n\nThere is not (yet) support for the \nCommon Workflow Language\n.\n\n\n\n\nHello World example\n\n\nLet's look at an example workflow to get a feel for what writing workflows in\nSciPipe looks like:\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n        \n// Import SciPipe, aliased to \nsp\n for brevity\n\n        \nsp\n \ngithub.com/scipipe/scipipe\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n        \n// Initialize processes from shell command patterns\n\n        \nhelloWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\nhelloWriter\n,\n \necho \nHello \n \n {o:hellofile}\n)\n\n        \nworldAppender\n \n:=\n \nsp\n.\nNewFromShell\n(\nworldAppender\n,\n \necho $(cat {i:infile}) World \n {o:worldfile}\n)\n\n        \n// Create a sink, that will just receive the final outputs\n\n        \nsink\n \n:=\n \nsp\n.\nNewSink\n()\n\n\n        \n// Configure output file path formatters for the processes created above\n\n        \nhelloWriter\n.\nSetPathStatic\n(\nhellofile\n,\n \nhello.txt\n)\n\n        \nworldAppender\n.\nSetPathReplace\n(\ninfile\n,\n \nworldfile\n,\n \n.txt\n,\n \n_world.txt\n)\n\n\n        \n// Connect network\n\n        \nworldAppender\n.\nIn\n[\ninfile\n].\nConnect\n(\nhelloWriter\n.\nOut\n[\nhellofile\n])\n\n        \nsink\n.\nConnect\n(\nworldAppender\n.\nOut\n[\nworldfile\n])\n\n\n        \n// Create a pipeline runner, add processes, and run\n\n        \npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n        \npipeline\n.\nAddProcesses\n(\nhelloWriter\n,\n \nworldAppender\n,\n \nsink\n)\n\n        \npipeline\n.\nRun\n()\n\n\n}\n\n\n\n\n\n\nRunning the example\n\n\nLet's put the code in a file named \nscipipe_helloworld.go\n and run it:\n\n\n$ go run scipipe_helloworld.go \nAUDIT   \n2017\n/05/04 \n17\n:05:15 Task:helloWriter  Executing command: \necho\n \nHello \n \n hello.txt.tmp\nAUDIT   \n2017\n/05/04 \n17\n:05:15 Task:worldAppender Executing command: \necho\n \n$(\ncat hello.txt\n)\n World \n hello_world.txt.tmp\n\n\n\n\n\nLet's check what file SciPipe has generated:\n\n\n$ ls -1tr hello*\nhello.txt.audit.json\nhello.txt\nhello_world.txt\nhello_world.txt.audit.json\n\n\n\n\n\nAs you can see, it has created a file \nhello.txt\n, and \nhello_world.txt\n, and\nan accompanying \n.audit.json\n for each of these files.\n\n\nNow, let's check the output of the final resulting file:\n\n\n$ cat hello_world.txt\nHello World\n\n\n\n\n\nNow we can rejoice that it contains the text \"Hello World\", exactly as a proper\nHello World example should :)\n\n\nYou can find many more examples in the \nexamples folder\n in the GitHub repo.\n\n\nFor more information about how to write workflows using SciPipe, use the menu\nto the left, to browse the various topics!", 
            "title": "Introduction"
        }, 
        {
            "location": "/#scipipe", 
            "text": "Project links:  GitHub Repo  |  Issue Tracker  |  Mailing List  \nSciPipe is a library for writing  Scientific\nWorkflows , sometimes\nalso called \"pipelines\", in the  Go programming language .  When you need to run many commandline programs that depend on each other in\ncomplex ways, SciPipe helps by making the process of running these programs\nflexible, robust and reproducible. SciPipe also lets you restart an interrupted\nrun without over-writing already produced output and produces an audit report\nof what was run, among many other things.  SciPipe is built on the proven principles of  Flow-Based\nProgramming  (FBP) to\nachieve maximum flexibility, productivity and agility when designing workflows.\nSimilar to other FBP systems, SciPipe workflows can be likened to a network of\nassembly lines in a factory, where items (files) are flowing through a network\nof conveyor belts, stopping at different independently running stations\n(processes) for processing, as depicted in the picture above.  SciPipe was initially created for problems in bioinformatics and\ncheminformatics, but works equally well for any problem involving pipelines of\ncommandline applications.", 
            "title": "SciPipe"
        }, 
        {
            "location": "/#benefits", 
            "text": "Some key benefits of SciPipe, that are not always found in similar systems:   Intuitive behaviour:  SciPipe operates by flowing data (files) through a\n  network of channels and processes, not unlike the conveyor belts and stations\n  in a factory.  Flexible:  Processes that wrap command-line programs or scripts, can be\n  combined with processes coded directly in Golang.  Custom file naming:  SciPipe gives you full control over how files are\n  named, making it easy to find your way among the output files of your\n  workflow.  Portable:  Workflows can be distributed either as Go code to be run with\n   go run , or as stand-alone executable files that run on almost any UNIX-like\n  operating system.  Easy to debug:  As everything in SciPipe is just Go code, you can use some\n  of the available debugging tools, or just  println()  statements, to debug\n  your workflow.   Supports streaming:  Can stream outputs via UNIX FIFO files, to avoid temporary storage.  Efficient and Parallel:  Workflows are compiled into statically compiled\n  code that runs fast. SciPipe also leverages pipeline parallelism between\n  processes as well as task parallelism when there are multiple inputs to a\n  process, making efficient use of multiple CPU cores.", 
            "title": "Benefits"
        }, 
        {
            "location": "/#known-limitations", 
            "text": "There are still a number of missing good-to-have features for workflow\n  design. See the  issue tracker \n  for details.  There is not (yet) support for the  Common Workflow Language .", 
            "title": "Known limitations"
        }, 
        {
            "location": "/#hello-world-example", 
            "text": "Let's look at an example workflow to get a feel for what writing workflows in\nSciPipe looks like:  package   main  import   ( \n         // Import SciPipe, aliased to  sp  for brevity \n         sp   github.com/scipipe/scipipe  )  func   main ()   { \n         // Initialize processes from shell command patterns \n         helloWriter   :=   sp . NewFromShell ( helloWriter ,   echo  Hello     {o:hellofile} ) \n         worldAppender   :=   sp . NewFromShell ( worldAppender ,   echo $(cat {i:infile}) World   {o:worldfile} ) \n         // Create a sink, that will just receive the final outputs \n         sink   :=   sp . NewSink () \n\n         // Configure output file path formatters for the processes created above \n         helloWriter . SetPathStatic ( hellofile ,   hello.txt ) \n         worldAppender . SetPathReplace ( infile ,   worldfile ,   .txt ,   _world.txt ) \n\n         // Connect network \n         worldAppender . In [ infile ]. Connect ( helloWriter . Out [ hellofile ]) \n         sink . Connect ( worldAppender . Out [ worldfile ]) \n\n         // Create a pipeline runner, add processes, and run \n         pipeline   :=   sp . NewPipelineRunner () \n         pipeline . AddProcesses ( helloWriter ,   worldAppender ,   sink ) \n         pipeline . Run ()  }", 
            "title": "Hello World example"
        }, 
        {
            "location": "/#running-the-example", 
            "text": "Let's put the code in a file named  scipipe_helloworld.go  and run it:  $ go run scipipe_helloworld.go \nAUDIT    2017 /05/04  17 :05:15 Task:helloWriter  Executing command:  echo   Hello     hello.txt.tmp\nAUDIT    2017 /05/04  17 :05:15 Task:worldAppender Executing command:  echo   $( cat hello.txt )  World   hello_world.txt.tmp  Let's check what file SciPipe has generated:  $ ls -1tr hello*\nhello.txt.audit.json\nhello.txt\nhello_world.txt\nhello_world.txt.audit.json  As you can see, it has created a file  hello.txt , and  hello_world.txt , and\nan accompanying  .audit.json  for each of these files.  Now, let's check the output of the final resulting file:  $ cat hello_world.txt\nHello World  Now we can rejoice that it contains the text \"Hello World\", exactly as a proper\nHello World example should :)  You can find many more examples in the  examples folder  in the GitHub repo.  For more information about how to write workflows using SciPipe, use the menu\nto the left, to browse the various topics!", 
            "title": "Running the example"
        }, 
        {
            "location": "/install/", 
            "text": "Installing SciPipe\n\n\nInstalling SciPipe means first installing the Go programming langauge, and then\nusing Go's \ngo get\n command to install the SciPipe library. After this, you will\nbe able to use Go's \ngo run\n command to run SciPipe workflows.\n\n\nInstall Go\n\n\nInstall Go by following the instructions \non this page\n,\nfor your operating system.\n\n\nInstall SciPipe\n\n\nThen install SciPipe by running the following shell command:\n\n\ngo get github.com/scipipe/scipipe/...\n\n\n\n\n\nN.B:\n Don't miss the \n...\n, as otherwise the \nscipipe\n helper tool will not be installed.\n\n\nInitialize a new workflow file\n\n\nNow, you should be able to write code like in the example below, in files ending with \n.go\n.\n\n\nThe easiest way to get started is to let the scipipe tool generate a starting point for you:\n\n\nscipipe new myfirstworkflow.go\n\n\n\n\n\n... which you can then edit to your liking.\n\n\nRun your workflow\n\n\nTo run a \n.go\n file, use \ngo run\n:\n\n\ngo run myfirstworkflow.go", 
            "title": "Installing"
        }, 
        {
            "location": "/install/#installing-scipipe", 
            "text": "Installing SciPipe means first installing the Go programming langauge, and then\nusing Go's  go get  command to install the SciPipe library. After this, you will\nbe able to use Go's  go run  command to run SciPipe workflows.", 
            "title": "Installing SciPipe"
        }, 
        {
            "location": "/install/#install-go", 
            "text": "Install Go by following the instructions  on this page ,\nfor your operating system.", 
            "title": "Install Go"
        }, 
        {
            "location": "/install/#install-scipipe", 
            "text": "Then install SciPipe by running the following shell command:  go get github.com/scipipe/scipipe/...  N.B:  Don't miss the  ... , as otherwise the  scipipe  helper tool will not be installed.", 
            "title": "Install SciPipe"
        }, 
        {
            "location": "/install/#initialize-a-new-workflow-file", 
            "text": "Now, you should be able to write code like in the example below, in files ending with  .go .  The easiest way to get started is to let the scipipe tool generate a starting point for you:  scipipe new myfirstworkflow.go  ... which you can then edit to your liking.", 
            "title": "Initialize a new workflow file"
        }, 
        {
            "location": "/install/#run-your-workflow", 
            "text": "To run a  .go  file, use  go run :  go run myfirstworkflow.go", 
            "title": "Run your workflow"
        }, 
        {
            "location": "/concepts/", 
            "text": "Basic concepts\n\n\nDefining workflows\n\n\nProcess overview\n\n\nDefining workflows in general (not unique to SciPipe) typically means:\n\n\n\n\nDefining the processes (or \"tasks\" or \"components\") of the workflow.\n\n\nDefining dependencies between the processes.\n\n\nRunning the workflow.\n\n\n\n\nMinimal boilerplate code\n\n\nIn Scipipe, everything is normal Go code, so SciPipe workflows are also\nfull, normal Go programs. These always need to do three things:\n\n\n\n\nDefine the \nmain\n package (always te case for executable files)\n\n\nImport the SciPipe library\n\n\nHave a \nmain()\n method, which contains the workflow code.\n\n\n\n\nThus, the minimal \"boilerplate\" code for any SciPipe workflow is a file\nnamed with the \n.go\n extension, and with this content:\n\n\npackage\n \nmain\n\n\n\nimport\n(\n\n    \ngithub.com/scipipe/scipipe\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \n// All workflow code goes here\n\n\n}\n\n\n\n\n\n\nThen, this file will be runnable with the \ngo run\n command, like:\n\n\ngo run myworkflow.go\n\n\n\n\n\nAliasing scipipe for less typing\n\n\nIf you find it tedious to type \nscipipe\n over and over in your code you can alias\nit to something shorter, like \nsp\n, by doing the import like this:\n\n\nimport\n(\n\n    \nsp\n \ngithub.com/scipipe/scipipe\n\n\n)\n\n\n\n\n\n\nDefining processes\n\n\nIn SciPipe, processes are defined using the \nNewFromShell()\n command, by\nproviding a process name and a shell pattern, where file names are replaced\nwith place-holders with a port-name. Just like so:\n\n\nmyProcess\n \n:=\n \nscipipe\n.\nNewFromShell\n(\nmyprocess\n,\n \necho hi \n {o:outfile}\n)\n\n\n\n\n\n\nBased on this shell command pattern, a process is created, with in- and\nout-ports and where the shell command to be executed, will be calculated from\nthe provided pattern.\n\n\nDefining dependencies\n\n\nThe dependency definitions in SciPipe are done by \"physically\" connecting ports\n(in-ports and out-ports) to each other via buffered channels, on which data\nobjects will travel between processes. The connection is done in practice with\na \nConnect()\n method, available on each port object, which takes another port\nobject as input, in order to connect the two ports.\n\n\nPorts created when using the shell pattern, are stored in the fields \nIn\n and\n\nOut\n on each process, under their own name, since the fields are maps.  So, an\nout-port named \"outfile\" will be accessed from \nmyProcess\n with:\n\nmyProcess.Out[\"outfile\"]\n, and and in-port named \"inport\" will be accessed from\n\nmyOhterProcess\n with: \nmyOtherProcess.In[\"infile\"]\n.\n\n\nConnecting \nmyOtherProcess.In[\"infile\"]\n with \nmyProcess.Out[\"outfile\"]\n is done\nsimply with:\n\n\nmyOtherProcess\n.\nIn\n[\ninfile\n].\nConnect\n(\nmyProcess\n.\nOut\n[\noutfile\n])\n\n\n\n\n\n\n... or\n\n\nmyProcess\n.\nOut\n[\noutfile\n].\nConnect\n(\nmyOtherProcess\n.\nIn\n[\ninfile\n])\n\n\n\n\n\n\n... since the operation is symmetric.\n\n\nThere is also an alternative syntax using the \nscipipe.Connect()\n method, which\ntakes two port-objects and connects them:\n\n\n```go\nscipipe.Connect(myOtherProcess.In[\ninfile\n], myProcess.Out[\noutfile\n])\n\n\n\n\n\n... or\n\n\nscipipe\n.\nConnect\n(\nmyProcess\n.\nOut\n[\noutfile\n],\n \nmyOtherProcess\n.\nIn\n[\ninfile\n])\n\n\n\n\n\n\nRunning workflows\n\n\nIn order to run SciPipe workflows, you have to add all processes to a pipeline runner,\nand then execute the \nRun()\n method on the pipeline runner, like so:\n\n\nrunner\n \n:=\n \nscipipe\n.\nNewPipelineRunner\n()\n\n\nrunner\n.\nAddProcesses\n(\nmyProcess\n,\n \nmyOtherProcess\n)\n\n\nrunner\n.\nRun\n()\n\n\n\n\n\n\nImportant:\n Note that the order processes are added to the pipeline runner is\nimportant!  The last process has to be added last, in order for the pipeline to\nfunction properly.\n\n\nNext steps\n\n\nPlease see the next section, \nWriting Workflows\n, for a\nconcrete example of using the concepts above.", 
            "title": "Basic Concepts"
        }, 
        {
            "location": "/concepts/#basic-concepts", 
            "text": "", 
            "title": "Basic concepts"
        }, 
        {
            "location": "/concepts/#defining-workflows", 
            "text": "", 
            "title": "Defining workflows"
        }, 
        {
            "location": "/concepts/#process-overview", 
            "text": "Defining workflows in general (not unique to SciPipe) typically means:   Defining the processes (or \"tasks\" or \"components\") of the workflow.  Defining dependencies between the processes.  Running the workflow.", 
            "title": "Process overview"
        }, 
        {
            "location": "/concepts/#minimal-boilerplate-code", 
            "text": "In Scipipe, everything is normal Go code, so SciPipe workflows are also\nfull, normal Go programs. These always need to do three things:   Define the  main  package (always te case for executable files)  Import the SciPipe library  Have a  main()  method, which contains the workflow code.   Thus, the minimal \"boilerplate\" code for any SciPipe workflow is a file\nnamed with the  .go  extension, and with this content:  package   main  import ( \n     github.com/scipipe/scipipe  )  func   main ()   { \n     // All workflow code goes here  }   Then, this file will be runnable with the  go run  command, like:  go run myworkflow.go", 
            "title": "Minimal boilerplate code"
        }, 
        {
            "location": "/concepts/#aliasing-scipipe-for-less-typing", 
            "text": "If you find it tedious to type  scipipe  over and over in your code you can alias\nit to something shorter, like  sp , by doing the import like this:  import ( \n     sp   github.com/scipipe/scipipe  )", 
            "title": "Aliasing scipipe for less typing"
        }, 
        {
            "location": "/concepts/#defining-processes", 
            "text": "In SciPipe, processes are defined using the  NewFromShell()  command, by\nproviding a process name and a shell pattern, where file names are replaced\nwith place-holders with a port-name. Just like so:  myProcess   :=   scipipe . NewFromShell ( myprocess ,   echo hi   {o:outfile} )   Based on this shell command pattern, a process is created, with in- and\nout-ports and where the shell command to be executed, will be calculated from\nthe provided pattern.", 
            "title": "Defining processes"
        }, 
        {
            "location": "/concepts/#defining-dependencies", 
            "text": "The dependency definitions in SciPipe are done by \"physically\" connecting ports\n(in-ports and out-ports) to each other via buffered channels, on which data\nobjects will travel between processes. The connection is done in practice with\na  Connect()  method, available on each port object, which takes another port\nobject as input, in order to connect the two ports.  Ports created when using the shell pattern, are stored in the fields  In  and Out  on each process, under their own name, since the fields are maps.  So, an\nout-port named \"outfile\" will be accessed from  myProcess  with: myProcess.Out[\"outfile\"] , and and in-port named \"inport\" will be accessed from myOhterProcess  with:  myOtherProcess.In[\"infile\"] .  Connecting  myOtherProcess.In[\"infile\"]  with  myProcess.Out[\"outfile\"]  is done\nsimply with:  myOtherProcess . In [ infile ]. Connect ( myProcess . Out [ outfile ])   ... or  myProcess . Out [ outfile ]. Connect ( myOtherProcess . In [ infile ])   ... since the operation is symmetric.  There is also an alternative syntax using the  scipipe.Connect()  method, which\ntakes two port-objects and connects them:  ```go\nscipipe.Connect(myOtherProcess.In[ infile ], myProcess.Out[ outfile ])  ... or  scipipe . Connect ( myProcess . Out [ outfile ],   myOtherProcess . In [ infile ])", 
            "title": "Defining dependencies"
        }, 
        {
            "location": "/concepts/#running-workflows", 
            "text": "In order to run SciPipe workflows, you have to add all processes to a pipeline runner,\nand then execute the  Run()  method on the pipeline runner, like so:  runner   :=   scipipe . NewPipelineRunner ()  runner . AddProcesses ( myProcess ,   myOtherProcess )  runner . Run ()   Important:  Note that the order processes are added to the pipeline runner is\nimportant!  The last process has to be added last, in order for the pipeline to\nfunction properly.", 
            "title": "Running workflows"
        }, 
        {
            "location": "/concepts/#next-steps", 
            "text": "Please see the next section,  Writing Workflows , for a\nconcrete example of using the concepts above.", 
            "title": "Next steps"
        }, 
        {
            "location": "/writing_workflows/", 
            "text": "Writing workflows with SciPipe\n\n\nAn example workflow\n\n\nBefore going into details about how to write SciPipe workflows, let's look at\nthe example workflow used on the front page, and use it as an example when we\ndiscuss the SciPipe syntax further below:\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \n// Import SciPipe, aliased to \nsp\n for brevity\n\n    \nsp\n \ngithub.com/scipipe/scipipe\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \n// Initialize processes from shell command patterns\n\n    \nhelloWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\nhelloWriter\n,\n \necho \nHello \n \n {o:hellofile}\n)\n\n    \nworldAppender\n \n:=\n \nsp\n.\nNewFromShell\n(\nworldAppender\n,\n \necho $(cat {i:infile}) World \n {o:worldfile}\n)\n\n    \n// Create a sink, that will just receive the final outputs\n\n    \nsink\n \n:=\n \nsp\n.\nNewSink\n()\n\n\n    \n// Configure output file path formatters for the processes created above\n\n    \nhelloWriter\n.\nSetPathStatic\n(\nhellofile\n,\n \nhello.txt\n)\n\n    \nworldAppender\n.\nSetPathReplace\n(\ninfile\n,\n \nworldfile\n,\n \n.txt\n,\n \n_world.txt\n)\n\n\n    \n// Connect network\n\n    \nworldAppender\n.\nIn\n[\ninfile\n].\nConnect\n(\nhelloWriter\n.\nOut\n[\nhellofile\n])\n\n    \nsink\n.\nConnect\n(\nworldAppender\n.\nOut\n[\nworldfile\n])\n\n\n    \n// Create a pipeline runner, add processes, and run\n\n    \npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n    \npipeline\n.\nAddProcesses\n(\nhelloWriter\n,\n \nworldAppender\n,\n \nsink\n)\n\n    \npipeline\n.\nRun\n()\n\n\n}\n\n\n\n\n\n\nLet's go through the code example step by step, and look in more\ndetail at what we are doing.\n\n\nInitializing processes\n\n\n// Initialize processes from shell command patterns\n\n\nhelloWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\nhelloWriter\n,\n \necho \nHello \n \n {o:hellofile}\n)\n\n\nworldAppender\n \n:=\n \nsp\n.\nNewFromShell\n(\nworldAppender\n,\n \necho $(cat {i:infile}) World \n {o:worldfile}\n)\n\n\n// Create a sink, that will just receive the final outputs\n\n\nsink\n \n:=\n \nsp\n.\nNewSink\n()\n\n\n\n\n\n\nHere we are initializing three new processes, two of them based on a shell\ncommand, and one \"sink\", which will just receive inputs adn nothing more.\n\n\nThe two first processes are created using the \nscipipe.NewFromShell()\n\nfunction, which takes a processname, and a shell command pattern as input.\n\n\nThe shell command pattern\n\n\nThe shell command patterns, in this case \necho 'Hello ' \n {o:hellofile}\n and\n\necho $(cat {i:infile}) World \n {o:worldfile}\n, are basically normal bash\nshell commands, with the addition of \"placeholders\" for input and output\nfilenames.\n\n\nInput filename placeholders are on the form \n{i:INPORT-NAME}\n and the output\nfilename placeholders are similarly of the form \n{o:OUTPORT-NAME}\n.  These\nplaceholders will be replaced with actual filenames when the command is\nexecuted later. The reason that it a port-name is used to name them, is that\nfiles will be queued on the channel connecting to the port, and for each set of\nfiles on in-ports, a command will be created and executed whereafter new files\nwill be pulled in on the out-ports, and so on.\n\n\nThe sink\n\n\nThe sink is needed in cases where the workflow ends with a process that is not\nan explicit endpoint without out-ports, such as a \"printer\" processes or\nsimilar, but instead has out-ports that need to be connected. Then the sink can\nbe used to receive from these out-ports so that the data packets on the\nout-ports don't get stuck and clog the workflow.\n\n\nFor these inports and outports, channels for sending and receiving FileTargets\nare automatically created and put in a hashmap added as a struct field of the\nprocess, named \nIn\n and \nOut\n repectively, Eash channel is added to the hashmap\nwith its inport/outport name as key in the hashmap, so that the channel can be\nretrieved from the hashmap using the in/outport name.\n\n\nFormatting output file paths\n\n\nNow we need to provide some way for scipipe to figure out a suitable file name\nfor each of the files propagating through the \"network\" of processes.  This can\nbe done using special convenience methods on the processes, starting with\n\nSetPath...\n. There are a few variants, of which two of them are shown here.\n\n\n// Configure output file path formatters for the processes created above\n\n\nhelloWriter\n.\nSetPathStatic\n(\nhellofile\n,\n \nhello.txt\n)\n\n\nworldAppender\n.\nSetPathReplace\n(\ninfile\n,\n \nworldfile\n,\n \n.txt\n,\n \n_world.txt\n)\n\n\n\n\n\n\nSetPathStatic\n just takes an out-port name and a static file name to use, and\nis suitable for processes which produce only one single output for a whole\nworkflow run.\n\n\nSetPathReplace\n is slightly more advanced: It takes an in-port name, and\nout-port name, and then a search-pattern in the input-filename, and a\nreplace-pattern for the output filename.  With the example above, our input\nfile named \nhello.txt\n will be converted into \nhello_world.txt\n by this path\npattern.\n\n\nEven more control over file formatting\n\n\nWe can actually get even more control over how file names are produced than\nthis, by manually supplying each process with an anonymous function that\nreturns file paths given a \nscipipe.SciTask\n object, which will be produced for\neach command execution.\n\n\nIn order to implement the same path patterns as above, using this method, we\nwould write like this: \n\n\n// Configure output file path formatters for the processes created above\n\n\nhelloWriter\n.\nPathFormatters\n[\nhellofile\n]\n \n=\n \nfunc\n(\nt\n \n*\nsp\n.\nSciTask\n)\n \nstring\n \n{\n\n\nreturn\n \nhello.txt\n\n\n}\n\n\nworldAppender\n.\nPathFormatters\n[\nworldfile\n]\n \n=\n \nfunc\n(\nt\n \n*\nsp\n.\nSciTask\n)\n \nstring\n \n{\n\n\nreturn\n \nstrings\n.\nReplace\n(\nt\n.\nInTargets\n[\ninfile\n].\nGetPath\n(),\n \n.txt\n,\n \n_world.txt\n,\n \n-\n1\n)\n\n\n}\n\n\n\n\n\n\nAs you can see, this is a much more complicated way to format paths, but it can\nbe useful for example when needing to incorporate parameter values into file\nnames.\n\n\nConnecting processes into a network\n\n\nFinally we need to define the data dependencies between our processes.  We do\nthis by connecting the outports of one process to the inport of another\nprocess, using the \nConnect\n method available on each port object. Sink objects\nhave a \nConnect\n method too, which take an out-port of an upstream process:\n\n\n// Connect network\n\n\nworldAppender\n.\nIn\n[\ninfile\n].\nConnect\n(\nhelloWriter\n.\nOut\n[\nhellofile\n])\n\n\nsink\n.\nConnect\n(\nworldAppender\n.\nOut\n[\nworldfile\n])\n\n\n\n\n\n\n(Note that the sink has the \nConnect\n method bound directly to itself, without\nany port).\n\n\nRunning the pipeline\n\n\nSo, the final part probably explains itself, but the pipeline runner component\nis a very simple one that will start each component except the last one in a\nseparate go-routine, while the last process will be run in the main go-routine,\nso as to block until the pipeline has finished.\n\n\n// Create a pipeline runner, add processes, and run\n\n\npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n\npipeline\n.\nAddProcesses\n(\nhelloWriter\n,\n \nworldAppender\n,\n \nsink\n)\n\n\npipeline\n.\nRun\n()\n\n\n\n\n\n\nSummary\n\n\nSo with this, we have done everything needed to set up a file-based batch workflow system.\n\n\nIn summary, what we did, was to:\n\n\n\n\nSpecify process dependencies by wiring outputs of the upstream processes to\n  inports in downstream processes.\n\n\nFor each outport, provide a function that will compute a suitable file name\n  for the new file.\n\n\n\n\nFor more examples, see the \nexamples folder\n.", 
            "title": "Writing Workflows"
        }, 
        {
            "location": "/writing_workflows/#writing-workflows-with-scipipe", 
            "text": "", 
            "title": "Writing workflows with SciPipe"
        }, 
        {
            "location": "/writing_workflows/#an-example-workflow", 
            "text": "Before going into details about how to write SciPipe workflows, let's look at\nthe example workflow used on the front page, and use it as an example when we\ndiscuss the SciPipe syntax further below:  package   main  import   ( \n     // Import SciPipe, aliased to  sp  for brevity \n     sp   github.com/scipipe/scipipe  )  func   main ()   { \n     // Initialize processes from shell command patterns \n     helloWriter   :=   sp . NewFromShell ( helloWriter ,   echo  Hello     {o:hellofile} ) \n     worldAppender   :=   sp . NewFromShell ( worldAppender ,   echo $(cat {i:infile}) World   {o:worldfile} ) \n     // Create a sink, that will just receive the final outputs \n     sink   :=   sp . NewSink () \n\n     // Configure output file path formatters for the processes created above \n     helloWriter . SetPathStatic ( hellofile ,   hello.txt ) \n     worldAppender . SetPathReplace ( infile ,   worldfile ,   .txt ,   _world.txt ) \n\n     // Connect network \n     worldAppender . In [ infile ]. Connect ( helloWriter . Out [ hellofile ]) \n     sink . Connect ( worldAppender . Out [ worldfile ]) \n\n     // Create a pipeline runner, add processes, and run \n     pipeline   :=   sp . NewPipelineRunner () \n     pipeline . AddProcesses ( helloWriter ,   worldAppender ,   sink ) \n     pipeline . Run ()  }   Let's go through the code example step by step, and look in more\ndetail at what we are doing.", 
            "title": "An example workflow"
        }, 
        {
            "location": "/writing_workflows/#initializing-processes", 
            "text": "// Initialize processes from shell command patterns  helloWriter   :=   sp . NewFromShell ( helloWriter ,   echo  Hello     {o:hellofile} )  worldAppender   :=   sp . NewFromShell ( worldAppender ,   echo $(cat {i:infile}) World   {o:worldfile} )  // Create a sink, that will just receive the final outputs  sink   :=   sp . NewSink ()   Here we are initializing three new processes, two of them based on a shell\ncommand, and one \"sink\", which will just receive inputs adn nothing more.  The two first processes are created using the  scipipe.NewFromShell() \nfunction, which takes a processname, and a shell command pattern as input.", 
            "title": "Initializing processes"
        }, 
        {
            "location": "/writing_workflows/#the-shell-command-pattern", 
            "text": "The shell command patterns, in this case  echo 'Hello '   {o:hellofile}  and echo $(cat {i:infile}) World   {o:worldfile} , are basically normal bash\nshell commands, with the addition of \"placeholders\" for input and output\nfilenames.  Input filename placeholders are on the form  {i:INPORT-NAME}  and the output\nfilename placeholders are similarly of the form  {o:OUTPORT-NAME} .  These\nplaceholders will be replaced with actual filenames when the command is\nexecuted later. The reason that it a port-name is used to name them, is that\nfiles will be queued on the channel connecting to the port, and for each set of\nfiles on in-ports, a command will be created and executed whereafter new files\nwill be pulled in on the out-ports, and so on.", 
            "title": "The shell command pattern"
        }, 
        {
            "location": "/writing_workflows/#the-sink", 
            "text": "The sink is needed in cases where the workflow ends with a process that is not\nan explicit endpoint without out-ports, such as a \"printer\" processes or\nsimilar, but instead has out-ports that need to be connected. Then the sink can\nbe used to receive from these out-ports so that the data packets on the\nout-ports don't get stuck and clog the workflow.  For these inports and outports, channels for sending and receiving FileTargets\nare automatically created and put in a hashmap added as a struct field of the\nprocess, named  In  and  Out  repectively, Eash channel is added to the hashmap\nwith its inport/outport name as key in the hashmap, so that the channel can be\nretrieved from the hashmap using the in/outport name.", 
            "title": "The sink"
        }, 
        {
            "location": "/writing_workflows/#formatting-output-file-paths", 
            "text": "Now we need to provide some way for scipipe to figure out a suitable file name\nfor each of the files propagating through the \"network\" of processes.  This can\nbe done using special convenience methods on the processes, starting with SetPath... . There are a few variants, of which two of them are shown here.  // Configure output file path formatters for the processes created above  helloWriter . SetPathStatic ( hellofile ,   hello.txt )  worldAppender . SetPathReplace ( infile ,   worldfile ,   .txt ,   _world.txt )   SetPathStatic  just takes an out-port name and a static file name to use, and\nis suitable for processes which produce only one single output for a whole\nworkflow run.  SetPathReplace  is slightly more advanced: It takes an in-port name, and\nout-port name, and then a search-pattern in the input-filename, and a\nreplace-pattern for the output filename.  With the example above, our input\nfile named  hello.txt  will be converted into  hello_world.txt  by this path\npattern.", 
            "title": "Formatting output file paths"
        }, 
        {
            "location": "/writing_workflows/#even-more-control-over-file-formatting", 
            "text": "We can actually get even more control over how file names are produced than\nthis, by manually supplying each process with an anonymous function that\nreturns file paths given a  scipipe.SciTask  object, which will be produced for\neach command execution.  In order to implement the same path patterns as above, using this method, we\nwould write like this:   // Configure output file path formatters for the processes created above  helloWriter . PathFormatters [ hellofile ]   =   func ( t   * sp . SciTask )   string   {  return   hello.txt  }  worldAppender . PathFormatters [ worldfile ]   =   func ( t   * sp . SciTask )   string   {  return   strings . Replace ( t . InTargets [ infile ]. GetPath (),   .txt ,   _world.txt ,   - 1 )  }   As you can see, this is a much more complicated way to format paths, but it can\nbe useful for example when needing to incorporate parameter values into file\nnames.", 
            "title": "Even more control over file formatting"
        }, 
        {
            "location": "/writing_workflows/#connecting-processes-into-a-network", 
            "text": "Finally we need to define the data dependencies between our processes.  We do\nthis by connecting the outports of one process to the inport of another\nprocess, using the  Connect  method available on each port object. Sink objects\nhave a  Connect  method too, which take an out-port of an upstream process:  // Connect network  worldAppender . In [ infile ]. Connect ( helloWriter . Out [ hellofile ])  sink . Connect ( worldAppender . Out [ worldfile ])   (Note that the sink has the  Connect  method bound directly to itself, without\nany port).", 
            "title": "Connecting processes into a network"
        }, 
        {
            "location": "/writing_workflows/#running-the-pipeline", 
            "text": "So, the final part probably explains itself, but the pipeline runner component\nis a very simple one that will start each component except the last one in a\nseparate go-routine, while the last process will be run in the main go-routine,\nso as to block until the pipeline has finished.  // Create a pipeline runner, add processes, and run  pipeline   :=   sp . NewPipelineRunner ()  pipeline . AddProcesses ( helloWriter ,   worldAppender ,   sink )  pipeline . Run ()", 
            "title": "Running the pipeline"
        }, 
        {
            "location": "/writing_workflows/#summary", 
            "text": "So with this, we have done everything needed to set up a file-based batch workflow system.  In summary, what we did, was to:   Specify process dependencies by wiring outputs of the upstream processes to\n  inports in downstream processes.  For each outport, provide a function that will compute a suitable file name\n  for the new file.   For more examples, see the  examples folder .", 
            "title": "Summary"
        }, 
        {
            "location": "/examples/", 
            "text": "Examples\n\n\nSee the \nexamples folder\n in the main scipipe repository.", 
            "title": "Examples"
        }, 
        {
            "location": "/examples/#examples", 
            "text": "See the  examples folder  in the main scipipe repository.", 
            "title": "Examples"
        }, 
        {
            "location": "/other_resources/", 
            "text": "Publications mentioning SciPipe\n\n\n\n\nSee \na poster on SciPipe\n, presented at the \ne-Science Academy in Lund, on Oct 12-13 2016\n.\n\n\nSee \nslides from a recent presentation of SciPipe for use in a Bioinformatics setting\n.\n\n\nThe architecture of SciPipe is based on an \nflow-based\n  programming\n like\n  pattern in pure Go presented in\n  \nthis\n and\n  \nthis\n\n  blog posts on Gopher Academy.", 
            "title": "Other resources"
        }, 
        {
            "location": "/other_resources/#publications-mentioning-scipipe", 
            "text": "See  a poster on SciPipe , presented at the  e-Science Academy in Lund, on Oct 12-13 2016 .  See  slides from a recent presentation of SciPipe for use in a Bioinformatics setting .  The architecture of SciPipe is based on an  flow-based\n  programming  like\n  pattern in pure Go presented in\n   this  and\n   this \n  blog posts on Gopher Academy.", 
            "title": "Publications mentioning SciPipe"
        }, 
        {
            "location": "/acknowledgements/", 
            "text": "Acknowledgements\n\n\n\n\nSciPipe is very heavily dependent on the proven principles form \nFlow-Based\n  Programming (FBP)\n, as invented by \nJohn Paul Morrison\n.\n  From Flow-based programming, SciPipe uses the ideas of separate network\n  (workflow dependency graph) definition, named in- and out-ports,\n  sub-networks/sub-workflows and bounded buffers (already available in Go's\n  channels) to make writing workflows as easy as possible.\n\n\nThis library is has been much influenced/inspired also by the\n  \nGoFlow\n library by \nVladimir Sibirov\n.\n\n\nThanks to \nEgon Elbre\n for helpful input on the\n  design of the internals of the pipeline, and processes, which greatly\n  simplified the implementation.\n\n\nThis work is financed by faculty grants and other financing for the \nPharmaceutical Bioinformatics group\n of \nDept. of\n  Pharmaceutical Biosciences\n at \nUppsala University\n, and by \nSwedish Research Council\n\n  through the Swedish \nNational Bioinformatics Infrastructure Sweden\n.\n\n\nSupervisor for the project is \nOla Spjuth\n.", 
            "title": "Acknowledgements"
        }, 
        {
            "location": "/acknowledgements/#acknowledgements", 
            "text": "SciPipe is very heavily dependent on the proven principles form  Flow-Based\n  Programming (FBP) , as invented by  John Paul Morrison .\n  From Flow-based programming, SciPipe uses the ideas of separate network\n  (workflow dependency graph) definition, named in- and out-ports,\n  sub-networks/sub-workflows and bounded buffers (already available in Go's\n  channels) to make writing workflows as easy as possible.  This library is has been much influenced/inspired also by the\n   GoFlow  library by  Vladimir Sibirov .  Thanks to  Egon Elbre  for helpful input on the\n  design of the internals of the pipeline, and processes, which greatly\n  simplified the implementation.  This work is financed by faculty grants and other financing for the  Pharmaceutical Bioinformatics group  of  Dept. of\n  Pharmaceutical Biosciences  at  Uppsala University , and by  Swedish Research Council \n  through the Swedish  National Bioinformatics Infrastructure Sweden .  Supervisor for the project is  Ola Spjuth .", 
            "title": "Acknowledgements"
        }, 
        {
            "location": "/related_tools/", 
            "text": "Related tools\n\n\nFind below a few tools that are more or less similar to SciPipe that are worth worth checking out before\ndeciding on what tool fits you best (in approximate order of similarity to SciPipe):\n\n\n\n\nNextFlow\n\n\nLuigi\n/\nSciLuigi\n\n\nBPipe\n\n\nSnakeMake\n\n\nCuneiform", 
            "title": "Related tools"
        }, 
        {
            "location": "/related_tools/#related-tools", 
            "text": "Find below a few tools that are more or less similar to SciPipe that are worth worth checking out before\ndeciding on what tool fits you best (in approximate order of similarity to SciPipe):   NextFlow  Luigi / SciLuigi  BPipe  SnakeMake  Cuneiform", 
            "title": "Related tools"
        }
    ]
}