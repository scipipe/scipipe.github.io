{
    "docs": [
        {
            "location": "/",
            "text": "SciPipe\n\n\n\n\n\n\nSciPipe is an experimental library for writing \nscientific Workflows\n in vanilla \nGo(lang)\n.\nThe architecture of SciPipe is based on an \nflow-based programming\n like pattern in pure Go as presented in\n\nthis\n and\n\nthis\n\nGopher Academy blog posts, and implemented in the\n\nFlowBase\n Flow-Based programming inspired micro\nframework, which SciPipe will be refactored to use, shortly.\n\n\nUPDATE Nov 4, 2016:\n See \na poster on SciPipe\n, presented at the \ne-Science Academy in Lund, on Oct 12-13 2016\n.\n\n\nUPDATE June 23, 2016:\n See also \nslides from a recent presentation of SciPipe for use in a Bioinformatics setting\n.\n\n\nAn example workflow\n\n\nLet's look at a simple toy example of a workflow, to get a feel for what\nwriting workflows with SciPipe looks like:\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nsp\n \n\"github.com/scipipe/scipipe\"\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \n// Initialize processes\n\n    \nfoo\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foowriter\"\n,\n \n\"echo 'foo' > {o:foo}\"\n)\n\n    \nf2b\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foo2bar\"\n,\n \n\"sed 's/foo/bar/g' {i:foo} > {o:bar}\"\n)\n\n    \nsnk\n \n:=\n \nsp\n.\nNewSink\n()\n \n// Will just receive file targets, doing nothing\n\n\n    \n// Add output file path formatters for the components created above\n\n    \nfoo\n.\nSetPathStatic\n(\n\"foo\"\n,\n \n\"foo.txt\"\n)\n\n    \nf2b\n.\nSetPathExtend\n(\n\"foo\"\n,\n \n\"bar\"\n,\n \n\".bar\"\n)\n\n\n    \n// Connect network\n\n    \nf2b\n.\nIn\n[\n\"foo\"\n].\nConnect\n(\nfoo\n.\nOut\n[\n\"foo\"\n])\n\n    \nsnk\n.\nConnect\n(\nf2b\n.\nOut\n[\n\"bar\"\n])\n\n\n    \n// Add to a pipeline runner and run\n\n    \npl\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n    \npl\n.\nAddProcesses\n(\nfoo\n,\n \nf2b\n,\n \nsnk\n)\n\n    \npl\n.\nRun\n()\n\n\n}\n\n\n\n\n\n\nRunning the example workflow\n\n\nLet's assume we put the code in a file named \nmyfirstworkflow.go\n and run it.\nThen it can look like this:\n\n\n[\nsamuel test\n]\n$ go run myfirstworkflow.go\nAUDIT   \n2016\n/06/09 \n17\n:17:41 Task:foowriter    Executing command: \necho\n \n'foo'\n > foo.txt.tmp\nAUDIT   \n2016\n/06/09 \n17\n:17:41 Task:foo2bar      Executing command: sed \n's/foo/bar/g'\n foo.txt > foo.txt.bar.tmp\n\n\n\n\n\nAs you see, scipipe displays all the shell commands it has executed based on the defined workflow.\n\n\nBenefits\n\n\nSome benefits of SciPipe that are not always available in other scientific workflow systems:\n\n\n\n\nEasy-to-grasp behaviour:\n Data flowing through a network.\n\n\nParallel:\n Apart from the inherent pipeline parallelism, SciPipe processes also spawn multiple parallel tasks when the same process has multiple inputs.\n\n\nConcurrent:\n Each process runs in an own light-weight thread, and is not blocked by\n  operations in other processes, except when waiting for inputs from upstream processes.\n\n\nInherently simple:\n Uses Go's concurrency primitives (go-routines and channels)\n  to create an \"implicit\" scheduler, which means very little additional infrastructure code.\n  This means that the code is easy to modify and extend.\n\n\nResource efficient:\n You can choose to stream selected outputs via Unix FIFO files, to avoid temporary storage.\n\n\nFlexible:\n Processes that wrap command-line programs and scripts can be combined with\n  processes coded directly in Golang.\n\n\nCustom file naming:\n SciPipe gives you full control over how file names are produced,\n  making it easy to understand and find your way among the output files of your computations.\n\n\nHighly Debuggable(!):\n Since everything in SciPipe is plain Go(lang), you can easily use the \ngdb debugger\n (preferrably\n  with the \ncgdb interface\n for easier use) to step through your program at any detail, as well as all\n  the other excellent debugging tooling for Go (See eg \ndelve\n and \ngodebug\n),\n  or just use \nprintln()\n statements at any place in your code. In addition, you can easily\n  turn on very detailed debug output from SciPipe's execution itself, by just turning on debug-level\n  logging with \nscipipe.InitLogDebug()\n in your \nmain()\n method.\n\n\nEfficient:\n Workflows are compiled into static compiled code, that runs fast.\n\n\nPortable:\n Workflows can be distributed as go code to be run with the \ngo run\n command\n  or compiled into stand-alone binaries for basically any unix-like operating system.\n\n\nNotebookeable:\n Works well in \nJupyter notebooks\n, using the \ngophernotes kernel\n (Thx \n@dwhitena\n for creating this!)\n\n\n\n\nKnown limitations\n\n\n\n\nThere are still a number of missing good-to-have features, for workflow design. See the \nissues\n tracker for details.\n\n\nThere is not yet support for the \nCommon Workflow Language\n, but that is also something that we plan to support in the future.\n\n\n\n\nConnection to flow-based programming\n\n\nFrom Flow-based programming, SciPipe uses the ideas of separate network (workflow dependency graph)\ndefinition, named in- and out-ports, sub-networks/sub-workflows and bounded buffers (already available\nin Go's channels) to make writing workflows as easy as possible.\n\n\nIn addition to that it adds convenience factory methods such as \nscipipe.NewFromShell()\n which creates ad hoc processes\non the fly based on a shell command pattern, where  inputs, outputs and parameters are defined in-line\nin the shell command with a syntax of \n{i:INPORT_NAME}\n for inports, and \n{o:OUTPORT_NAME}\n for outports\nand \n{p:PARAM_NAME}\n for parameters.\n\n\nRelated tools\n\n\nFind below a few tools that are more or less similar to SciPipe that are worth worth checking out before\ndeciding on what tool fits you best (in approximate order of similarity to SciPipe):\n\n\n\n\nNextFlow\n\n\nLuigi\n/\nSciLuigi\n\n\nBPipe\n\n\nSnakeMake\n\n\nCuneiform\n\n\n\n\nAcknowledgements\n\n\n\n\nThis library is heavily influenced/inspired by (and might make use of on in the future),\n  the \nGoFlow\n library by \nVladimir Sibirov\n.\n\n\nIt is also heavily influenced by the \nFlow-based programming\n by \nJohn Paul Morrison\n.\n\n\nThis work is financed by faculty grants and other financing for Jarl Wikberg's \nPharmaceutical Bioinformatics group\n of Dept. of\n  Pharmaceutical Biosciences at Uppsala University, and to a smaller part also by \nSwedish Research Council\n through the Swedish \nBioinformatics Infastructure for Life Sciences in Sweden\n.\n\n\nSupervisor for the project is \nOla Spjuth\n.\n\n\nBig thanks to \nEgon Elbre\n for very helpful input on the design of the internals of the pipeline, and processes, which simplified the implementation a lot.",
            "title": "SciPipe Overview"
        },
        {
            "location": "/#scipipe",
            "text": "SciPipe is an experimental library for writing  scientific Workflows  in vanilla  Go(lang) .\nThe architecture of SciPipe is based on an  flow-based programming  like pattern in pure Go as presented in this  and this \nGopher Academy blog posts, and implemented in the FlowBase  Flow-Based programming inspired micro\nframework, which SciPipe will be refactored to use, shortly.  UPDATE Nov 4, 2016:  See  a poster on SciPipe , presented at the  e-Science Academy in Lund, on Oct 12-13 2016 .  UPDATE June 23, 2016:  See also  slides from a recent presentation of SciPipe for use in a Bioinformatics setting .",
            "title": "SciPipe"
        },
        {
            "location": "/#an-example-workflow",
            "text": "Let's look at a simple toy example of a workflow, to get a feel for what\nwriting workflows with SciPipe looks like:  package   main  import   ( \n     sp   \"github.com/scipipe/scipipe\"  )  func   main ()   { \n     // Initialize processes \n     foo   :=   sp . NewFromShell ( \"foowriter\" ,   \"echo 'foo' > {o:foo}\" ) \n     f2b   :=   sp . NewFromShell ( \"foo2bar\" ,   \"sed 's/foo/bar/g' {i:foo} > {o:bar}\" ) \n     snk   :=   sp . NewSink ()   // Will just receive file targets, doing nothing \n\n     // Add output file path formatters for the components created above \n     foo . SetPathStatic ( \"foo\" ,   \"foo.txt\" ) \n     f2b . SetPathExtend ( \"foo\" ,   \"bar\" ,   \".bar\" ) \n\n     // Connect network \n     f2b . In [ \"foo\" ]. Connect ( foo . Out [ \"foo\" ]) \n     snk . Connect ( f2b . Out [ \"bar\" ]) \n\n     // Add to a pipeline runner and run \n     pl   :=   sp . NewPipelineRunner () \n     pl . AddProcesses ( foo ,   f2b ,   snk ) \n     pl . Run ()  }",
            "title": "An example workflow"
        },
        {
            "location": "/#running-the-example-workflow",
            "text": "Let's assume we put the code in a file named  myfirstworkflow.go  and run it.\nThen it can look like this:  [ samuel test ] $ go run myfirstworkflow.go\nAUDIT    2016 /06/09  17 :17:41 Task:foowriter    Executing command:  echo   'foo'  > foo.txt.tmp\nAUDIT    2016 /06/09  17 :17:41 Task:foo2bar      Executing command: sed  's/foo/bar/g'  foo.txt > foo.txt.bar.tmp  As you see, scipipe displays all the shell commands it has executed based on the defined workflow.",
            "title": "Running the example workflow"
        },
        {
            "location": "/#benefits",
            "text": "Some benefits of SciPipe that are not always available in other scientific workflow systems:   Easy-to-grasp behaviour:  Data flowing through a network.  Parallel:  Apart from the inherent pipeline parallelism, SciPipe processes also spawn multiple parallel tasks when the same process has multiple inputs.  Concurrent:  Each process runs in an own light-weight thread, and is not blocked by\n  operations in other processes, except when waiting for inputs from upstream processes.  Inherently simple:  Uses Go's concurrency primitives (go-routines and channels)\n  to create an \"implicit\" scheduler, which means very little additional infrastructure code.\n  This means that the code is easy to modify and extend.  Resource efficient:  You can choose to stream selected outputs via Unix FIFO files, to avoid temporary storage.  Flexible:  Processes that wrap command-line programs and scripts can be combined with\n  processes coded directly in Golang.  Custom file naming:  SciPipe gives you full control over how file names are produced,\n  making it easy to understand and find your way among the output files of your computations.  Highly Debuggable(!):  Since everything in SciPipe is plain Go(lang), you can easily use the  gdb debugger  (preferrably\n  with the  cgdb interface  for easier use) to step through your program at any detail, as well as all\n  the other excellent debugging tooling for Go (See eg  delve  and  godebug ),\n  or just use  println()  statements at any place in your code. In addition, you can easily\n  turn on very detailed debug output from SciPipe's execution itself, by just turning on debug-level\n  logging with  scipipe.InitLogDebug()  in your  main()  method.  Efficient:  Workflows are compiled into static compiled code, that runs fast.  Portable:  Workflows can be distributed as go code to be run with the  go run  command\n  or compiled into stand-alone binaries for basically any unix-like operating system.  Notebookeable:  Works well in  Jupyter notebooks , using the  gophernotes kernel  (Thx  @dwhitena  for creating this!)",
            "title": "Benefits"
        },
        {
            "location": "/#known-limitations",
            "text": "There are still a number of missing good-to-have features, for workflow design. See the  issues  tracker for details.  There is not yet support for the  Common Workflow Language , but that is also something that we plan to support in the future.",
            "title": "Known limitations"
        },
        {
            "location": "/#connection-to-flow-based-programming",
            "text": "From Flow-based programming, SciPipe uses the ideas of separate network (workflow dependency graph)\ndefinition, named in- and out-ports, sub-networks/sub-workflows and bounded buffers (already available\nin Go's channels) to make writing workflows as easy as possible.  In addition to that it adds convenience factory methods such as  scipipe.NewFromShell()  which creates ad hoc processes\non the fly based on a shell command pattern, where  inputs, outputs and parameters are defined in-line\nin the shell command with a syntax of  {i:INPORT_NAME}  for inports, and  {o:OUTPORT_NAME}  for outports\nand  {p:PARAM_NAME}  for parameters.",
            "title": "Connection to flow-based programming"
        },
        {
            "location": "/#related-tools",
            "text": "Find below a few tools that are more or less similar to SciPipe that are worth worth checking out before\ndeciding on what tool fits you best (in approximate order of similarity to SciPipe):   NextFlow  Luigi / SciLuigi  BPipe  SnakeMake  Cuneiform",
            "title": "Related tools"
        },
        {
            "location": "/#acknowledgements",
            "text": "This library is heavily influenced/inspired by (and might make use of on in the future),\n  the  GoFlow  library by  Vladimir Sibirov .  It is also heavily influenced by the  Flow-based programming  by  John Paul Morrison .  This work is financed by faculty grants and other financing for Jarl Wikberg's  Pharmaceutical Bioinformatics group  of Dept. of\n  Pharmaceutical Biosciences at Uppsala University, and to a smaller part also by  Swedish Research Council  through the Swedish  Bioinformatics Infastructure for Life Sciences in Sweden .  Supervisor for the project is  Ola Spjuth .  Big thanks to  Egon Elbre  for very helpful input on the design of the internals of the pipeline, and processes, which simplified the implementation a lot.",
            "title": "Acknowledgements"
        },
        {
            "location": "/install/",
            "text": "Install\n\n\nInstall Go\n\n\nFirst install Go by following instructions on \nthis page\n.\n  - I typically install to a custom location (\n~/go\n for the go tools, and \n~/code/go\n for my own go-projects).\n  - If you want to install (which means, untar the go tarball) to \n~/go\n just like me, you should put the following in your \n~/.bashrc\n file:\n\n\n# Go stuff\n\n\nexport\n \nGOROOT\n=\n~/go\n\nexport\n \nGOPATH\n=\n~/code/go\n\nexport\n \nPATH\n=\n$GOROOT\n/bin:\n$PATH\n\n\nexport\n \nPATH\n=\n$GOPATH\n/bin:\n$PATH\n\n\n\n\n\n\nInstall SciPipe\n\n\nInstall SciPipe by running the following shell command:\n\n\ngo get github.com/scipipe/scipipe/...\n\n\n\n\n\nN.B:\n Don't miss the \n...\n, or you won't get the \nscipipe\n helper tool.\n\n\nInitialize a new workflow file\n\n\nNow, you should be able to write code like in the example below, in files ending with \n.go\n.\n\n\nThe easiest way to get started is to let the scipipe tool generate a starting point for you:\n\n\nscipipe new myfirstworkflow.go\n\n\n\n\n\n... which you can then edit to your liking.\n\n\nRun your workflow\n\n\nTo run a \n.go\n file, use \ngo run\n:\n\n\ngo run myfirstworkflow.go",
            "title": "Installing SciPipe"
        },
        {
            "location": "/install/#install",
            "text": "",
            "title": "Install"
        },
        {
            "location": "/install/#install-go",
            "text": "First install Go by following instructions on  this page .\n  - I typically install to a custom location ( ~/go  for the go tools, and  ~/code/go  for my own go-projects).\n  - If you want to install (which means, untar the go tarball) to  ~/go  just like me, you should put the following in your  ~/.bashrc  file:  # Go stuff  export   GOROOT = ~/go export   GOPATH = ~/code/go export   PATH = $GOROOT /bin: $PATH  export   PATH = $GOPATH /bin: $PATH",
            "title": "Install Go"
        },
        {
            "location": "/install/#install-scipipe",
            "text": "Install SciPipe by running the following shell command:  go get github.com/scipipe/scipipe/...  N.B:  Don't miss the  ... , or you won't get the  scipipe  helper tool.",
            "title": "Install SciPipe"
        },
        {
            "location": "/install/#initialize-a-new-workflow-file",
            "text": "Now, you should be able to write code like in the example below, in files ending with  .go .  The easiest way to get started is to let the scipipe tool generate a starting point for you:  scipipe new myfirstworkflow.go  ... which you can then edit to your liking.",
            "title": "Initialize a new workflow file"
        },
        {
            "location": "/install/#run-your-workflow",
            "text": "To run a  .go  file, use  go run :  go run myfirstworkflow.go",
            "title": "Run your workflow"
        },
        {
            "location": "/writing_workflows/",
            "text": "Writing workflows with SciPipe\n\n\nAn example workflow\n\n\nBefore going into details about how to write SciPipe workflows, let's look at\nthe example workflow used on the front page, and use it as an example when we\ndiscuss the SciPipe syntax further below:\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nsp\n \n\"github.com/scipipe/scipipe\"\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \n// Initialize processes\n\n    \nfoo\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foowriter\"\n,\n \n\"echo 'foo' > {o:foo}\"\n)\n\n    \nf2b\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foo2bar\"\n,\n \n\"sed 's/foo/bar/g' {i:foo} > {o:bar}\"\n)\n\n    \nsnk\n \n:=\n \nsp\n.\nNewSink\n()\n \n// Will just receive file targets, doing nothing\n\n\n    \n// Add output file path formatters for the components created above\n\n    \nfoo\n.\nSetPathStatic\n(\n\"foo\"\n,\n \n\"foo.txt\"\n)\n\n    \nf2b\n.\nSetPathExtend\n(\n\"foo\"\n,\n \n\"bar\"\n,\n \n\".bar\"\n)\n\n\n    \n// Connect network\n\n    \nf2b\n.\nIn\n[\n\"foo\"\n].\nConnect\n(\nfoo\n.\nOut\n[\n\"foo\"\n])\n\n    \nsnk\n.\nConnect\n(\nf2b\n.\nOut\n[\n\"bar\"\n])\n\n\n    \n// Add to a pipeline runner and run\n\n    \npl\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n    \npl\n.\nAddProcesses\n(\nfoo\n,\n \nf2b\n,\n \nsnk\n)\n\n    \npl\n.\nRun\n()\n\n\n}\n\n\n\n\n\n\nLet us now go through the code example step by step, and describe in more\ndetail what we are doing.\n\n\nInitializing processes\n\n\nfoo\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foowriter\"\n,\n \n\"echo 'foo' > {o:out}\"\n)\n\n\nf2b\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foo2bar\"\n,\n \n\"sed 's/foo/bar/g' {i:foo} > {o:bar}\"\n)\n\n\nsnk\n \n:=\n \nsp\n.\nNewSink\n()\n \n// Will just receive file targets, doing nothing\n\n\n\n\n\n\nFor these inports and outports, channels for sending and receiving FileTargets are automatically\ncreated and put in a hashmap added as a struct field of the process, named \nIn\n and \nOut\n repectively,\nEash channel is added to the hashmap with its inport/outport name as key in the hashmap,\nso that the channel can be retrieved from the hashmap using the in/outport name.\n\n\nConnecting processes into a network\n\n\nConnecting outports of one process to the inport of another process is then\ndone with the \nConnect\n method available on each port object. Sink objects have\na \nConnect\n method too:\n\n\nf2b\n.\nIn\n[\n\"foo\"\n].\nConnect\n(\nfoo\n.\nOut\n[\n\"foo\"\n])\n\n\nsnk\n.\nConnect\n(\nf2b\n.\nOut\n[\n\"bar\"\n])\n\n\n\n\n\n\n(Note that the sink has just one inport, as a static struct field).\n\n\nFormatting output file paths\n\n\nThe only thing remaining after this, is to provide some way for the program to figure out a\nsuitable file name for each of the files propagating through this little \"network\" of processes.\nThis is done by adding a closure (function) to another special hashmap, again keyed by\nthe names of the outports of the processes. So, to define the output filenames of the two processes\nabove, we would add:\n\n\nfoo\n.\nPathFormatters\n[\n\"foo\"\n]\n \n=\n \nfunc\n(\nt\n \n*\nsp\n.\nSciTask\n)\n \nstring\n \n{\n\n    \n// Just statically create a file named foo.txt\n\n    \nreturn\n \n\"foo.txt\"\n\n\n}\n\n\nf2b\n.\nPathFormatters\n[\n\"bar\"\n]\n \n=\n \nfunc\n(\nt\n \n*\nsp\n.\nSciTask\n)\n \nstring\n \n{\n\n    \n// Here, we instead re-use the file name of the process we depend\n\n    \n// on (which we get on the 'foo' inport), and just\n\n    \n// pad '.bar' at the end:\n\n    \nreturn\n \nf2b\n.\nGetInPath\n(\n\"foo\"\n)\n \n+\n \n\".bar\"\n\n\n}\n\n\n\n\n\n\nFormatting output file paths: A nicer way\n\n\nNow, the above way of defining path formats is a bit verbose, isn't it?\nLuckily, there's a shorter way, by using convenience methods for doing the same\nthing. So, the above two path formats can also be defined like so, with the exact same result:\n\n\n// Create a static file name for the out-port 'foo':\n\n\nfoo\n.\nSetPathStatic\n(\n\"foo\"\n,\n \n\"foo.txt\"\n)\n\n\n\n// For out-port 'bar', extend the file names of files on in-port 'foo', with\n\n\n// the suffix '.bar':\n\n\nf2b\n.\nSetPathExtend\n(\n\"foo\"\n,\n \n\"bar\"\n,\n \n\".bar\"\n)\n\n\n\n\n\n\nRunning the pipeline\n\n\nSo, the final part probably explains itself, but the pipeline runner component\nis a very simple one that will start each component except the last one in a\nseparate go-routine, while the last process will be run in the main go-routine,\nso as to block until the pipeline has finished.\n\n\npl\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n\npl\n.\nAddProcesses\n(\nfoo\n,\n \nf2b\n,\n \nsnk\n)\n\n\npl\n.\nRun\n()\n\n\n\n\n\n\nSummary\n\n\nSo with this, we have done everything needed to set up a file-based batch workflow system.\n\n\nIn summary, what we did, was to:\n\n\n\n\nSpecify process dependencies by wiring outputs of the upstream processes to inports in downstream processes.\n\n\nFor each outport, provide a function that will compute a suitable file name for the new file.\n\n\n\n\nFor more examples, see the \nexamples folder\n.",
            "title": "Writing Workflows"
        },
        {
            "location": "/writing_workflows/#writing-workflows-with-scipipe",
            "text": "",
            "title": "Writing workflows with SciPipe"
        },
        {
            "location": "/writing_workflows/#an-example-workflow",
            "text": "Before going into details about how to write SciPipe workflows, let's look at\nthe example workflow used on the front page, and use it as an example when we\ndiscuss the SciPipe syntax further below:  package   main  import   ( \n     sp   \"github.com/scipipe/scipipe\"  )  func   main ()   { \n     // Initialize processes \n     foo   :=   sp . NewFromShell ( \"foowriter\" ,   \"echo 'foo' > {o:foo}\" ) \n     f2b   :=   sp . NewFromShell ( \"foo2bar\" ,   \"sed 's/foo/bar/g' {i:foo} > {o:bar}\" ) \n     snk   :=   sp . NewSink ()   // Will just receive file targets, doing nothing \n\n     // Add output file path formatters for the components created above \n     foo . SetPathStatic ( \"foo\" ,   \"foo.txt\" ) \n     f2b . SetPathExtend ( \"foo\" ,   \"bar\" ,   \".bar\" ) \n\n     // Connect network \n     f2b . In [ \"foo\" ]. Connect ( foo . Out [ \"foo\" ]) \n     snk . Connect ( f2b . Out [ \"bar\" ]) \n\n     // Add to a pipeline runner and run \n     pl   :=   sp . NewPipelineRunner () \n     pl . AddProcesses ( foo ,   f2b ,   snk ) \n     pl . Run ()  }   Let us now go through the code example step by step, and describe in more\ndetail what we are doing.",
            "title": "An example workflow"
        },
        {
            "location": "/writing_workflows/#initializing-processes",
            "text": "foo   :=   sp . NewFromShell ( \"foowriter\" ,   \"echo 'foo' > {o:out}\" )  f2b   :=   sp . NewFromShell ( \"foo2bar\" ,   \"sed 's/foo/bar/g' {i:foo} > {o:bar}\" )  snk   :=   sp . NewSink ()   // Will just receive file targets, doing nothing   For these inports and outports, channels for sending and receiving FileTargets are automatically\ncreated and put in a hashmap added as a struct field of the process, named  In  and  Out  repectively,\nEash channel is added to the hashmap with its inport/outport name as key in the hashmap,\nso that the channel can be retrieved from the hashmap using the in/outport name.",
            "title": "Initializing processes"
        },
        {
            "location": "/writing_workflows/#connecting-processes-into-a-network",
            "text": "Connecting outports of one process to the inport of another process is then\ndone with the  Connect  method available on each port object. Sink objects have\na  Connect  method too:  f2b . In [ \"foo\" ]. Connect ( foo . Out [ \"foo\" ])  snk . Connect ( f2b . Out [ \"bar\" ])   (Note that the sink has just one inport, as a static struct field).",
            "title": "Connecting processes into a network"
        },
        {
            "location": "/writing_workflows/#formatting-output-file-paths",
            "text": "The only thing remaining after this, is to provide some way for the program to figure out a\nsuitable file name for each of the files propagating through this little \"network\" of processes.\nThis is done by adding a closure (function) to another special hashmap, again keyed by\nthe names of the outports of the processes. So, to define the output filenames of the two processes\nabove, we would add:  foo . PathFormatters [ \"foo\" ]   =   func ( t   * sp . SciTask )   string   { \n     // Just statically create a file named foo.txt \n     return   \"foo.txt\"  }  f2b . PathFormatters [ \"bar\" ]   =   func ( t   * sp . SciTask )   string   { \n     // Here, we instead re-use the file name of the process we depend \n     // on (which we get on the 'foo' inport), and just \n     // pad '.bar' at the end: \n     return   f2b . GetInPath ( \"foo\" )   +   \".bar\"  }",
            "title": "Formatting output file paths"
        },
        {
            "location": "/writing_workflows/#formatting-output-file-paths-a-nicer-way",
            "text": "Now, the above way of defining path formats is a bit verbose, isn't it?\nLuckily, there's a shorter way, by using convenience methods for doing the same\nthing. So, the above two path formats can also be defined like so, with the exact same result:  // Create a static file name for the out-port 'foo':  foo . SetPathStatic ( \"foo\" ,   \"foo.txt\" )  // For out-port 'bar', extend the file names of files on in-port 'foo', with  // the suffix '.bar':  f2b . SetPathExtend ( \"foo\" ,   \"bar\" ,   \".bar\" )",
            "title": "Formatting output file paths: A nicer way"
        },
        {
            "location": "/writing_workflows/#running-the-pipeline",
            "text": "So, the final part probably explains itself, but the pipeline runner component\nis a very simple one that will start each component except the last one in a\nseparate go-routine, while the last process will be run in the main go-routine,\nso as to block until the pipeline has finished.  pl   :=   sp . NewPipelineRunner ()  pl . AddProcesses ( foo ,   f2b ,   snk )  pl . Run ()",
            "title": "Running the pipeline"
        },
        {
            "location": "/writing_workflows/#summary",
            "text": "So with this, we have done everything needed to set up a file-based batch workflow system.  In summary, what we did, was to:   Specify process dependencies by wiring outputs of the upstream processes to inports in downstream processes.  For each outport, provide a function that will compute a suitable file name for the new file.   For more examples, see the  examples folder .",
            "title": "Summary"
        },
        {
            "location": "/examples/",
            "text": "Examples\n\n\nSee the \nexamples folder\n in the main scipipe repository.",
            "title": "Examples"
        },
        {
            "location": "/examples/#examples",
            "text": "See the  examples folder  in the main scipipe repository.",
            "title": "Examples"
        }
    ]
}