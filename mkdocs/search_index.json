{
    "docs": [
        {
            "location": "/",
            "text": "SciPipe\n\n\n\n\nProject links: [ \nGitHub Repo\n | \nIssue Tracker\n | \nMailing List\n ]\n\n\n\nSciPipe is a library for writing \nScientific\nWorkflows\n, or\n\"pipelines\", in the \nGo programming language\n.\n\n\nWhen you need to run many commandline programs that depend on each other in\ncomplex ways, SciPipe helps to make running these programs in a flexible,\nrobust and reproducible way, even letting you restart an interrupted run\nwithout over-writing already produced output, among many other things.\n\n\nSciPipe is built on the proven principles of \nFlow-Based\nProgramming\n (FBP) to\nachieve maximum flexibility, productivity and agility when designing workflows.\nSimilar to other FBP systems, SciPipe workflows can be likened to a network of\nassembly lines in a factory, where items (files) are flowing through a network\nof conveyor belts, stopping at different independently running stations\n(processes) for processing, as depicted in the picture above.\n\n\nBenefits\n\n\nSome key benefits of SciPipe, that are not always found in similar systems:\n\n\n\n\nIntuitive behaviour:\n SciPipe operates by flowing data (files) through a\n  network of channels and processes, not unlike the conveyor belts and stations\n  in a factory.\n\n\nFlexible:\n Processes that wrap command-line programs or scripts, can be\n  combined with processes coded directly in Golang.\n\n\nCustom file naming:\n SciPipe gives you full control over how files are\n  named, making it easy to find your way among the output files of your\n  workflow.\n\n\nPortable:\n Workflows can be distributed either as Go code to be run with\n  \ngo run\n, or as stand-alone executable files that run on almost any UNIX-like\n  operating system.\n\n\nEasy to debug:\n As everything in SciPipe is just Go code, you can use some\n  of the available debugging tools, or just \nprintln()\n statements, to debug\n  your workflow. \n\n\nSupports streaming:\n Can stream outputs via UNIX FIFO files, to avoid temporary storage.\n\n\nEfficient and Parallel:\n Workflows are compiled into statically compiled\n  code that runs fast. SciPipe also leverages pipeline parallelism between\n  processes as well as task parallelism when there are multiple inputs to a\n  process, making efficient use of multiple CPU cores.\n\n\n\n\nKnown limitations\n\n\n\n\nThere are still a number of missing good-to-have features for workflow\n  design. See the \nissue tracker\n\n  for details.\n\n\nThere is not (yet) support for the \nCommon Workflow Language\n.\n\n\n\n\nHello World example\n\n\nLet's look at an example workflow to get a feel for what writing workflows in\nSciPipe looks like:\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n        \n// Import SciPipe, aliased to 'sp' for brevity\n\n        \nsp\n \n\"github.com/scipipe/scipipe\"\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n        \n// Initialize processes from shell command patterns\n\n        \nhelloWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"helloWriter\"\n,\n \n\"echo 'Hello ' > {o:hellofile}\"\n)\n\n        \nworldAppender\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"worldAppender\"\n,\n \n\"echo $(cat {i:infile}) World >> {o:worldfile}\"\n)\n\n        \n// Create a sink, that will just receive the final outputs\n\n        \nsink\n \n:=\n \nsp\n.\nNewSink\n()\n\n\n        \n// Configure output file path formatters for the processes created above\n\n        \nhelloWriter\n.\nSetPathStatic\n(\n\"hellofile\"\n,\n \n\"hello.txt\"\n)\n\n        \nworldAppender\n.\nSetPathReplace\n(\n\"infile\"\n,\n \n\"worldfile\"\n,\n \n\".txt\"\n,\n \n\"_world.txt\"\n)\n\n\n        \n// Connect network\n\n        \nworldAppender\n.\nIn\n[\n\"infile\"\n].\nConnect\n(\nhelloWriter\n.\nOut\n[\n\"hellofile\"\n])\n\n        \nsink\n.\nConnect\n(\nworldAppender\n.\nOut\n[\n\"worldfile\"\n])\n\n\n        \n// Create a pipeline runner, add processes, and run\n\n        \npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n        \npipeline\n.\nAddProcesses\n(\nhelloWriter\n,\n \nworldAppender\n,\n \nsink\n)\n\n        \npipeline\n.\nRun\n()\n\n\n}\n\n\n\n\n\n\nRunning the example\n\n\nLet's put the code in a file named \nscipipe_helloworld.go\n and run it:\n\n\n$ go run scipipe_helloworld.go \nAUDIT   \n2017\n/05/04 \n17\n:05:15 Task:helloWriter  Executing command: \necho\n \n'Hello '\n > hello.txt.tmp\nAUDIT   \n2017\n/05/04 \n17\n:05:15 Task:worldAppender Executing command: \necho\n \n$(\ncat hello.txt\n)\n World >> hello_world.txt.tmp\n\n\n\n\n\nLet's check what file SciPipe has generated:\n\n\n$ ls -1tr hello*\nhello.txt.audit.json\nhello.txt\nhello_world.txt\nhello_world.txt.audit.json\n\n\n\n\n\nAs you can see, it has created a file \nhello.txt\n, and \nhello_world.txt\n, and\nan accompanying \n.audit.json\n for both of these files.\n\n\nNow, let's check the output of the final resulting file:\n\n\n$ cat hello_world.txt\nHello World\n\n\n\n\n\nNow we can rejoice that it contains the text \"Hello World\", exactly as a proper\nHello World example should :)\n\n\nYou can find many more examples in the \nexamples folder\n in the GitHub repo.\n\n\nFor more information about how to write workflows using SciPipe, use the menu\nto the left, to browse the various topics!",
            "title": "SciPipe Overview"
        },
        {
            "location": "/#scipipe",
            "text": "Project links: [  GitHub Repo  |  Issue Tracker  |  Mailing List  ]  \nSciPipe is a library for writing  Scientific\nWorkflows , or\n\"pipelines\", in the  Go programming language .  When you need to run many commandline programs that depend on each other in\ncomplex ways, SciPipe helps to make running these programs in a flexible,\nrobust and reproducible way, even letting you restart an interrupted run\nwithout over-writing already produced output, among many other things.  SciPipe is built on the proven principles of  Flow-Based\nProgramming  (FBP) to\nachieve maximum flexibility, productivity and agility when designing workflows.\nSimilar to other FBP systems, SciPipe workflows can be likened to a network of\nassembly lines in a factory, where items (files) are flowing through a network\nof conveyor belts, stopping at different independently running stations\n(processes) for processing, as depicted in the picture above.",
            "title": "SciPipe"
        },
        {
            "location": "/#benefits",
            "text": "Some key benefits of SciPipe, that are not always found in similar systems:   Intuitive behaviour:  SciPipe operates by flowing data (files) through a\n  network of channels and processes, not unlike the conveyor belts and stations\n  in a factory.  Flexible:  Processes that wrap command-line programs or scripts, can be\n  combined with processes coded directly in Golang.  Custom file naming:  SciPipe gives you full control over how files are\n  named, making it easy to find your way among the output files of your\n  workflow.  Portable:  Workflows can be distributed either as Go code to be run with\n   go run , or as stand-alone executable files that run on almost any UNIX-like\n  operating system.  Easy to debug:  As everything in SciPipe is just Go code, you can use some\n  of the available debugging tools, or just  println()  statements, to debug\n  your workflow.   Supports streaming:  Can stream outputs via UNIX FIFO files, to avoid temporary storage.  Efficient and Parallel:  Workflows are compiled into statically compiled\n  code that runs fast. SciPipe also leverages pipeline parallelism between\n  processes as well as task parallelism when there are multiple inputs to a\n  process, making efficient use of multiple CPU cores.",
            "title": "Benefits"
        },
        {
            "location": "/#known-limitations",
            "text": "There are still a number of missing good-to-have features for workflow\n  design. See the  issue tracker \n  for details.  There is not (yet) support for the  Common Workflow Language .",
            "title": "Known limitations"
        },
        {
            "location": "/#hello-world-example",
            "text": "Let's look at an example workflow to get a feel for what writing workflows in\nSciPipe looks like:  package   main  import   ( \n         // Import SciPipe, aliased to 'sp' for brevity \n         sp   \"github.com/scipipe/scipipe\"  )  func   main ()   { \n         // Initialize processes from shell command patterns \n         helloWriter   :=   sp . NewFromShell ( \"helloWriter\" ,   \"echo 'Hello ' > {o:hellofile}\" ) \n         worldAppender   :=   sp . NewFromShell ( \"worldAppender\" ,   \"echo $(cat {i:infile}) World >> {o:worldfile}\" ) \n         // Create a sink, that will just receive the final outputs \n         sink   :=   sp . NewSink () \n\n         // Configure output file path formatters for the processes created above \n         helloWriter . SetPathStatic ( \"hellofile\" ,   \"hello.txt\" ) \n         worldAppender . SetPathReplace ( \"infile\" ,   \"worldfile\" ,   \".txt\" ,   \"_world.txt\" ) \n\n         // Connect network \n         worldAppender . In [ \"infile\" ]. Connect ( helloWriter . Out [ \"hellofile\" ]) \n         sink . Connect ( worldAppender . Out [ \"worldfile\" ]) \n\n         // Create a pipeline runner, add processes, and run \n         pipeline   :=   sp . NewPipelineRunner () \n         pipeline . AddProcesses ( helloWriter ,   worldAppender ,   sink ) \n         pipeline . Run ()  }",
            "title": "Hello World example"
        },
        {
            "location": "/#running-the-example",
            "text": "Let's put the code in a file named  scipipe_helloworld.go  and run it:  $ go run scipipe_helloworld.go \nAUDIT    2017 /05/04  17 :05:15 Task:helloWriter  Executing command:  echo   'Hello '  > hello.txt.tmp\nAUDIT    2017 /05/04  17 :05:15 Task:worldAppender Executing command:  echo   $( cat hello.txt )  World >> hello_world.txt.tmp  Let's check what file SciPipe has generated:  $ ls -1tr hello*\nhello.txt.audit.json\nhello.txt\nhello_world.txt\nhello_world.txt.audit.json  As you can see, it has created a file  hello.txt , and  hello_world.txt , and\nan accompanying  .audit.json  for both of these files.  Now, let's check the output of the final resulting file:  $ cat hello_world.txt\nHello World  Now we can rejoice that it contains the text \"Hello World\", exactly as a proper\nHello World example should :)  You can find many more examples in the  examples folder  in the GitHub repo.  For more information about how to write workflows using SciPipe, use the menu\nto the left, to browse the various topics!",
            "title": "Running the example"
        },
        {
            "location": "/install/",
            "text": "Install\n\n\nInstall Go\n\n\nFirst install Go by following instructions on \nthis page\n.\n  - I typically install to a custom location (\n~/go\n for the go tools, and \n~/code/go\n for my own go-projects).\n  - If you want to install (which means, untar the go tarball) to \n~/go\n just like me, you should put the following in your \n~/.bashrc\n file:\n\n\n# Go stuff\n\n\nexport\n \nGOROOT\n=\n~/go\n\nexport\n \nGOPATH\n=\n~/code/go\n\nexport\n \nPATH\n=\n$GOROOT\n/bin:\n$PATH\n\n\nexport\n \nPATH\n=\n$GOPATH\n/bin:\n$PATH\n\n\n\n\n\n\nInstall SciPipe\n\n\nInstall SciPipe by running the following shell command:\n\n\ngo get github.com/scipipe/scipipe/...\n\n\n\n\n\nN.B:\n Don't miss the \n...\n, or you won't get the \nscipipe\n helper tool.\n\n\nInitialize a new workflow file\n\n\nNow, you should be able to write code like in the example below, in files ending with \n.go\n.\n\n\nThe easiest way to get started is to let the scipipe tool generate a starting point for you:\n\n\nscipipe new myfirstworkflow.go\n\n\n\n\n\n... which you can then edit to your liking.\n\n\nRun your workflow\n\n\nTo run a \n.go\n file, use \ngo run\n:\n\n\ngo run myfirstworkflow.go",
            "title": "Installing SciPipe"
        },
        {
            "location": "/install/#install",
            "text": "",
            "title": "Install"
        },
        {
            "location": "/install/#install-go",
            "text": "First install Go by following instructions on  this page .\n  - I typically install to a custom location ( ~/go  for the go tools, and  ~/code/go  for my own go-projects).\n  - If you want to install (which means, untar the go tarball) to  ~/go  just like me, you should put the following in your  ~/.bashrc  file:  # Go stuff  export   GOROOT = ~/go export   GOPATH = ~/code/go export   PATH = $GOROOT /bin: $PATH  export   PATH = $GOPATH /bin: $PATH",
            "title": "Install Go"
        },
        {
            "location": "/install/#install-scipipe",
            "text": "Install SciPipe by running the following shell command:  go get github.com/scipipe/scipipe/...  N.B:  Don't miss the  ... , or you won't get the  scipipe  helper tool.",
            "title": "Install SciPipe"
        },
        {
            "location": "/install/#initialize-a-new-workflow-file",
            "text": "Now, you should be able to write code like in the example below, in files ending with  .go .  The easiest way to get started is to let the scipipe tool generate a starting point for you:  scipipe new myfirstworkflow.go  ... which you can then edit to your liking.",
            "title": "Initialize a new workflow file"
        },
        {
            "location": "/install/#run-your-workflow",
            "text": "To run a  .go  file, use  go run :  go run myfirstworkflow.go",
            "title": "Run your workflow"
        },
        {
            "location": "/writing_workflows/",
            "text": "Writing workflows with SciPipe\n\n\nAn example workflow\n\n\nBefore going into details about how to write SciPipe workflows, let's look at\nthe example workflow used on the front page, and use it as an example when we\ndiscuss the SciPipe syntax further below:\n\n\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nsp\n \n\"github.com/scipipe/scipipe\"\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \n// Initialize processes\n\n    \nfooWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foowriter\"\n,\n \n\"echo 'foo' > {o:foo}\"\n)\n\n    \nfooToBar\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foo2bar\"\n,\n \n\"sed 's/foo/bar/g' {i:foo} > {o:bar}\"\n)\n\n    \nsink\n \n:=\n \nsp\n.\nNewSink\n()\n \n// Will just receive file targets, doing nothing\n\n\n    \n// Add output file path formatters for the components created above\n\n    \nfooWriter\n.\nSetPathStatic\n(\n\"foo\"\n,\n \n\"foo.txt\"\n)\n\n    \nfooToBar\n.\nSetPathExtend\n(\n\"foo\"\n,\n \n\"bar\"\n,\n \n\".bar\"\n)\n\n\n    \n// Connect network\n\n    \nfooToBar\n.\nIn\n[\n\"foo\"\n].\nConnect\n(\nfooWriter\n.\nOut\n[\n\"foo\"\n])\n\n    \nsink\n.\nConnect\n(\nfooToBar\n.\nOut\n[\n\"bar\"\n])\n\n\n    \n// Add to a pipeline runner and run\n\n    \npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n    \npipeline\n.\nAddProcesses\n(\nfooWriter\n,\n \nfooToBar\n,\n \nsink\n)\n\n    \npipeline\n.\nRun\n()\n\n\n}\n\n\n\n\n\n\nLet us now go through the code example step by step, and describe in more\ndetail what we are doing.\n\n\nInitializing processes\n\n\nfooWriter\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foowriter\"\n,\n \n\"echo 'foo' > {o:out}\"\n)\n\n\nfooToBar\n \n:=\n \nsp\n.\nNewFromShell\n(\n\"foo2bar\"\n,\n \n\"sed 's/foo/bar/g' {i:foo} > {o:bar}\"\n)\n\n\nsink\n \n:=\n \nsp\n.\nNewSink\n()\n \n// Will just receive file targets, doing nothing\n\n\n\n\n\n\nFor these inports and outports, channels for sending and receiving FileTargets are automatically\ncreated and put in a hashmap added as a struct field of the process, named \nIn\n and \nOut\n repectively,\nEash channel is added to the hashmap with its inport/outport name as key in the hashmap,\nso that the channel can be retrieved from the hashmap using the in/outport name.\n\n\nConnecting processes into a network\n\n\nConnecting outports of one process to the inport of another process is then\ndone with the \nConnect\n method available on each port object. Sink objects have\na \nConnect\n method too:\n\n\nfooToBar\n.\nIn\n[\n\"foo\"\n].\nConnect\n(\nfooWriter\n.\nOut\n[\n\"foo\"\n])\n\n\nsink\n.\nConnect\n(\nfooToBar\n.\nOut\n[\n\"bar\"\n])\n\n\n\n\n\n\n(Note that the sink has just one inport, as a static struct field).\n\n\nFormatting output file paths\n\n\nThe only thing remaining after this, is to provide some way for the program to figure out a\nsuitable file name for each of the files propagating through this little \"network\" of processes.\nThis is done by adding a closure (function) to another special hashmap, again keyed by\nthe names of the outports of the processes. So, to define the output filenames of the two processes\nabove, we would add:\n\n\nfooWriter\n.\nPathFormatters\n[\n\"foo\"\n]\n \n=\n \nfunc\n(\nt\n \n*\nsp\n.\nSciTask\n)\n \nstring\n \n{\n\n    \n// Just statically create a file named foo.txt\n\n    \nreturn\n \n\"foo.txt\"\n\n\n}\n\n\nfooToBar\n.\nPathFormatters\n[\n\"bar\"\n]\n \n=\n \nfunc\n(\nt\n \n*\nsp\n.\nSciTask\n)\n \nstring\n \n{\n\n    \n// Here, we instead re-use the file name of the process we depend\n\n    \n// on (which we get on the 'foo' inport), and just\n\n    \n// pad '.bar' at the end:\n\n    \nreturn\n \nfooToBar\n.\nGetInPath\n(\n\"foo\"\n)\n \n+\n \n\".bar\"\n\n\n}\n\n\n\n\n\n\nFormatting output file paths: A nicer way\n\n\nNow, the above way of defining path formats is a bit verbose, isn't it?\nLuckily, there's a shorter way, by using convenience methods for doing the same\nthing. So, the above two path formats can also be defined like so, with the exact same result:\n\n\n// Create a static file name for the out-port 'foo':\n\n\nfooWriter\n.\nSetPathStatic\n(\n\"foo\"\n,\n \n\"foo.txt\"\n)\n\n\n\n// For out-port 'bar', extend the file names of files on in-port 'foo', with\n\n\n// the suffix '.bar':\n\n\nfooToBar\n.\nSetPathExtend\n(\n\"foo\"\n,\n \n\"bar\"\n,\n \n\".bar\"\n)\n\n\n\n\n\n\nRunning the pipeline\n\n\nSo, the final part probably explains itself, but the pipeline runner component\nis a very simple one that will start each component except the last one in a\nseparate go-routine, while the last process will be run in the main go-routine,\nso as to block until the pipeline has finished.\n\n\npipeline\n \n:=\n \nsp\n.\nNewPipelineRunner\n()\n\n\npipeline\n.\nAddProcesses\n(\nfooWriter\n,\n \nfooToBar\n,\n \nsink\n)\n\n\npipeline\n.\nRun\n()\n\n\n\n\n\n\nSummary\n\n\nSo with this, we have done everything needed to set up a file-based batch workflow system.\n\n\nIn summary, what we did, was to:\n\n\n\n\nSpecify process dependencies by wiring outputs of the upstream processes to inports in downstream processes.\n\n\nFor each outport, provide a function that will compute a suitable file name for the new file.\n\n\n\n\nFor more examples, see the \nexamples folder\n.",
            "title": "Writing Workflows"
        },
        {
            "location": "/writing_workflows/#writing-workflows-with-scipipe",
            "text": "",
            "title": "Writing workflows with SciPipe"
        },
        {
            "location": "/writing_workflows/#an-example-workflow",
            "text": "Before going into details about how to write SciPipe workflows, let's look at\nthe example workflow used on the front page, and use it as an example when we\ndiscuss the SciPipe syntax further below:  package   main  import   ( \n     sp   \"github.com/scipipe/scipipe\"  )  func   main ()   { \n     // Initialize processes \n     fooWriter   :=   sp . NewFromShell ( \"foowriter\" ,   \"echo 'foo' > {o:foo}\" ) \n     fooToBar   :=   sp . NewFromShell ( \"foo2bar\" ,   \"sed 's/foo/bar/g' {i:foo} > {o:bar}\" ) \n     sink   :=   sp . NewSink ()   // Will just receive file targets, doing nothing \n\n     // Add output file path formatters for the components created above \n     fooWriter . SetPathStatic ( \"foo\" ,   \"foo.txt\" ) \n     fooToBar . SetPathExtend ( \"foo\" ,   \"bar\" ,   \".bar\" ) \n\n     // Connect network \n     fooToBar . In [ \"foo\" ]. Connect ( fooWriter . Out [ \"foo\" ]) \n     sink . Connect ( fooToBar . Out [ \"bar\" ]) \n\n     // Add to a pipeline runner and run \n     pipeline   :=   sp . NewPipelineRunner () \n     pipeline . AddProcesses ( fooWriter ,   fooToBar ,   sink ) \n     pipeline . Run ()  }   Let us now go through the code example step by step, and describe in more\ndetail what we are doing.",
            "title": "An example workflow"
        },
        {
            "location": "/writing_workflows/#initializing-processes",
            "text": "fooWriter   :=   sp . NewFromShell ( \"foowriter\" ,   \"echo 'foo' > {o:out}\" )  fooToBar   :=   sp . NewFromShell ( \"foo2bar\" ,   \"sed 's/foo/bar/g' {i:foo} > {o:bar}\" )  sink   :=   sp . NewSink ()   // Will just receive file targets, doing nothing   For these inports and outports, channels for sending and receiving FileTargets are automatically\ncreated and put in a hashmap added as a struct field of the process, named  In  and  Out  repectively,\nEash channel is added to the hashmap with its inport/outport name as key in the hashmap,\nso that the channel can be retrieved from the hashmap using the in/outport name.",
            "title": "Initializing processes"
        },
        {
            "location": "/writing_workflows/#connecting-processes-into-a-network",
            "text": "Connecting outports of one process to the inport of another process is then\ndone with the  Connect  method available on each port object. Sink objects have\na  Connect  method too:  fooToBar . In [ \"foo\" ]. Connect ( fooWriter . Out [ \"foo\" ])  sink . Connect ( fooToBar . Out [ \"bar\" ])   (Note that the sink has just one inport, as a static struct field).",
            "title": "Connecting processes into a network"
        },
        {
            "location": "/writing_workflows/#formatting-output-file-paths",
            "text": "The only thing remaining after this, is to provide some way for the program to figure out a\nsuitable file name for each of the files propagating through this little \"network\" of processes.\nThis is done by adding a closure (function) to another special hashmap, again keyed by\nthe names of the outports of the processes. So, to define the output filenames of the two processes\nabove, we would add:  fooWriter . PathFormatters [ \"foo\" ]   =   func ( t   * sp . SciTask )   string   { \n     // Just statically create a file named foo.txt \n     return   \"foo.txt\"  }  fooToBar . PathFormatters [ \"bar\" ]   =   func ( t   * sp . SciTask )   string   { \n     // Here, we instead re-use the file name of the process we depend \n     // on (which we get on the 'foo' inport), and just \n     // pad '.bar' at the end: \n     return   fooToBar . GetInPath ( \"foo\" )   +   \".bar\"  }",
            "title": "Formatting output file paths"
        },
        {
            "location": "/writing_workflows/#formatting-output-file-paths-a-nicer-way",
            "text": "Now, the above way of defining path formats is a bit verbose, isn't it?\nLuckily, there's a shorter way, by using convenience methods for doing the same\nthing. So, the above two path formats can also be defined like so, with the exact same result:  // Create a static file name for the out-port 'foo':  fooWriter . SetPathStatic ( \"foo\" ,   \"foo.txt\" )  // For out-port 'bar', extend the file names of files on in-port 'foo', with  // the suffix '.bar':  fooToBar . SetPathExtend ( \"foo\" ,   \"bar\" ,   \".bar\" )",
            "title": "Formatting output file paths: A nicer way"
        },
        {
            "location": "/writing_workflows/#running-the-pipeline",
            "text": "So, the final part probably explains itself, but the pipeline runner component\nis a very simple one that will start each component except the last one in a\nseparate go-routine, while the last process will be run in the main go-routine,\nso as to block until the pipeline has finished.  pipeline   :=   sp . NewPipelineRunner ()  pipeline . AddProcesses ( fooWriter ,   fooToBar ,   sink )  pipeline . Run ()",
            "title": "Running the pipeline"
        },
        {
            "location": "/writing_workflows/#summary",
            "text": "So with this, we have done everything needed to set up a file-based batch workflow system.  In summary, what we did, was to:   Specify process dependencies by wiring outputs of the upstream processes to inports in downstream processes.  For each outport, provide a function that will compute a suitable file name for the new file.   For more examples, see the  examples folder .",
            "title": "Summary"
        },
        {
            "location": "/examples/",
            "text": "Examples\n\n\nSee the \nexamples folder\n in the main scipipe repository.",
            "title": "Examples"
        },
        {
            "location": "/examples/#examples",
            "text": "See the  examples folder  in the main scipipe repository.",
            "title": "Examples"
        },
        {
            "location": "/known_limitations/",
            "text": "Known limitations\n\n\n\n\nThere are still a number of missing good-to-have features, for workflow design. See the \nissues\n tracker for details.\n\n\nThere is not yet support for the \nCommon Workflow Language\n, but that is also something that we plan to support in the future.",
            "title": "Known limitations"
        },
        {
            "location": "/known_limitations/#known-limitations",
            "text": "There are still a number of missing good-to-have features, for workflow design. See the  issues  tracker for details.  There is not yet support for the  Common Workflow Language , but that is also something that we plan to support in the future.",
            "title": "Known limitations"
        },
        {
            "location": "/flow_based_programming/",
            "text": "Connection to Flow-Based Programming\n\n\nFrom Flow-based programming, SciPipe uses the ideas of separate network (workflow dependency graph)\ndefinition, named in- and out-ports, sub-networks/sub-workflows and bounded buffers (already available\nin Go's channels) to make writing workflows as easy as possible.",
            "title": "Flow-Based Programming"
        },
        {
            "location": "/flow_based_programming/#connection-to-flow-based-programming",
            "text": "From Flow-based programming, SciPipe uses the ideas of separate network (workflow dependency graph)\ndefinition, named in- and out-ports, sub-networks/sub-workflows and bounded buffers (already available\nin Go's channels) to make writing workflows as easy as possible.",
            "title": "Connection to Flow-Based Programming"
        },
        {
            "location": "/other_resources/",
            "text": "Publications mentioning SciPipe\n\n\n\n\nSee \na poster on SciPipe\n, presented at the \ne-Science Academy in Lund, on Oct 12-13 2016\n.\n\n\nSee \nslides from a recent presentation of SciPipe for use in a Bioinformatics setting\n.\n\n\nThe architecture of SciPipe is based on an \nflow-based\n  programming\n like\n  pattern in pure Go presented in\n  \nthis\n and\n  \nthis\n\n  blog posts on Gopher Academy.",
            "title": "Other resources"
        },
        {
            "location": "/other_resources/#publications-mentioning-scipipe",
            "text": "See  a poster on SciPipe , presented at the  e-Science Academy in Lund, on Oct 12-13 2016 .  See  slides from a recent presentation of SciPipe for use in a Bioinformatics setting .  The architecture of SciPipe is based on an  flow-based\n  programming  like\n  pattern in pure Go presented in\n   this  and\n   this \n  blog posts on Gopher Academy.",
            "title": "Publications mentioning SciPipe"
        },
        {
            "location": "/acknowledgements/",
            "text": "Acknowledgements\n\n\n\n\nThis library is heavily influenced/inspired by (and might make use of on in the future),\n  the \nGoFlow\n library by \nVladimir Sibirov\n.\n\n\nIt is also heavily influenced by the \nFlow-based programming\n by \nJohn Paul Morrison\n.\n\n\nThis work is financed by faculty grants and other financing for Jarl Wikberg's \nPharmaceutical Bioinformatics group\n of Dept. of\n  Pharmaceutical Biosciences at Uppsala University, and to a smaller part also by \nSwedish Research Council\n through the Swedish \nBioinformatics Infastructure for Life Sciences in Sweden\n.\n\n\nSupervisor for the project is \nOla Spjuth\n.\n\n\nBig thanks to \nEgon Elbre\n for very helpful input on the design of the internals of the pipeline, and processes, which simplified the implementation a lot.",
            "title": "Acknowledgements"
        },
        {
            "location": "/acknowledgements/#acknowledgements",
            "text": "This library is heavily influenced/inspired by (and might make use of on in the future),\n  the  GoFlow  library by  Vladimir Sibirov .  It is also heavily influenced by the  Flow-based programming  by  John Paul Morrison .  This work is financed by faculty grants and other financing for Jarl Wikberg's  Pharmaceutical Bioinformatics group  of Dept. of\n  Pharmaceutical Biosciences at Uppsala University, and to a smaller part also by  Swedish Research Council  through the Swedish  Bioinformatics Infastructure for Life Sciences in Sweden .  Supervisor for the project is  Ola Spjuth .  Big thanks to  Egon Elbre  for very helpful input on the design of the internals of the pipeline, and processes, which simplified the implementation a lot.",
            "title": "Acknowledgements"
        },
        {
            "location": "/related_tools/",
            "text": "Related tools\n\n\nFind below a few tools that are more or less similar to SciPipe that are worth worth checking out before\ndeciding on what tool fits you best (in approximate order of similarity to SciPipe):\n\n\n\n\nNextFlow\n\n\nLuigi\n/\nSciLuigi\n\n\nBPipe\n\n\nSnakeMake\n\n\nCuneiform",
            "title": "Related tool"
        },
        {
            "location": "/related_tools/#related-tools",
            "text": "Find below a few tools that are more or less similar to SciPipe that are worth worth checking out before\ndeciding on what tool fits you best (in approximate order of similarity to SciPipe):   NextFlow  Luigi / SciLuigi  BPipe  SnakeMake  Cuneiform",
            "title": "Related tools"
        }
    ]
}